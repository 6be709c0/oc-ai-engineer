{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "import json  \n",
    "import sys  \n",
    "\n",
    "import seaborn as sns  \n",
    "import matplotlib.pyplot as plt  \n",
    "\n",
    "from nltk.stem.snowball import EnglishStemmer\n",
    "import plotly.express as px  \n",
    "from sklearn.preprocessing import LabelEncoder  \n",
    "\n",
    "# nltk.download('punkt')\n",
    "# nltk.download('stopwords')\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, GlobalAveragePooling1D, Flatten, Dense, Dropout \n",
    "from tensorflow.keras.layers import Rescaling, RandomFlip, RandomRotation, RandomZoom\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.applications.vgg19 import VGG19\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input as preprocess_input_vgg16\n",
    "from tensorflow.keras.applications.vgg19 import preprocess_input as preprocess_input_vgg19\n",
    "from tensorflow.keras.preprocessing.image import load_img  as load_img, img_to_array  as img_to_array\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from glob import glob\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TEXTE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recupérer et explorer les données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Je commence par lire mon fichier d'entrée"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./../input/flipkart_com-ecommerce_sample_1050.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Shape is\", df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Je n'ai pas besoin de toute les colonnes, je conserve que ce qui m'interesse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[[\"uniq_id\",\"product_name\",\"product_category_tree\", \"description\"]]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Je mets les categories sous forme de colonne hierachique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to split and create the category columns dynamically  \n",
    "def create_category_columns(row):\n",
    "    json_categories = json.loads(row[\"product_category_tree\"])\n",
    "    if(len(json_categories) > 1):\n",
    "        print(\"Categories array > 1, update the script to cover that.\")\n",
    "        sys.exit(1)  \n",
    "\n",
    "    split_categories = json_categories[0].split(\">>\")\n",
    "    \n",
    "    for i, category in enumerate(split_categories):\n",
    "        column_name = f\"category_lvl_{i + 1}\"  \n",
    "        row[column_name] = category.strip().lower()\n",
    "    return row\n",
    "\n",
    "# Apply the funcion to all rows\n",
    "df = df.assign(**df.apply(lambda row: create_category_columns(row), axis=1))  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"category_lvl_3\"].fillna(\"undefined\",inplace=True)\n",
    "df[\"category_lvl_4\"].fillna(\"undefined\",inplace=True)\n",
    "df[\"category_lvl_5\"].fillna(\"undefined\",inplace=True)\n",
    "df[\"category_lvl_6\"].fillna(\"undefined\",inplace=True)\n",
    "df[\"category_lvl_7\"].fillna(\"undefined\",inplace=True)\n",
    "df.isna().sum()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Je regarde la distribution de mes valeurs sur la première catégorie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['category_lvl_1'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'df' is your DataFrame  \n",
    "category_counts = df['category_lvl_1'].value_counts()  \n",
    "  \n",
    "# Set color palette from seaborn  \n",
    "colors = sns.color_palette('Set3')  \n",
    "  \n",
    "# Create pie chart  \n",
    "plt.figure(figsize=(5, 5))  \n",
    "plt.pie(category_counts, labels=category_counts.index, autopct='%1.1f%%', startangle=90, colors=colors)  \n",
    "plt.axis('equal')  \n",
    "plt.title(\"Value counts of 'category_lvl_1'\")  \n",
    "  \n",
    "# Show the chart  \n",
    "plt.show()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La distribution est similaire pour chaque produits, j'affiche la 2e catégorie via le graphique sunburst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.sunburst(df, path=['category_lvl_1', 'category_lvl_2'])\n",
    "\n",
    "fig.update_layout(  \n",
    "    margin=dict(t=0, l=0, r=0, b=0),  \n",
    "    width=500,  \n",
    "    height=500,  \n",
    "    title=\"Zoomable Sunburst Chart\"  \n",
    ")  \n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Je visualize avec Treemap pour observer la différence de rendu avec sunburst pour utiliser lors de la présentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.treemap(df, path=['category_lvl_1', 'category_lvl_2', 'category_lvl_3'])  \n",
    "  \n",
    "fig.update_layout(  \n",
    "    margin=dict(t=0, l=0, r=0, b=0),  \n",
    "    width=800,  \n",
    "    height=600,  \n",
    "    title=\"Treemap Chart\"  \n",
    ")  \n",
    "  \n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Je suis ok au niveau de la visualisation, ce qui m'interesse sera de classifier uniquement la catégorie lvl 1.  \n",
    "Je vais donc mettre à jour mon dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[[\"uniq_id\", \"product_name\", \"description\", \"category_lvl_1\"]]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "J'effectue maintenant un label encoding sur mes categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.rename(columns={'category_lvl_1': 'cat'})\n",
    "original_df = df.copy()\n",
    "\n",
    "encoder = LabelEncoder()  \n",
    "df[\"cat_e\"] = encoder.fit_transform(df[\"cat\"])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Je vérifie si j'ai des doublons dans la description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = df.duplicated(subset=\"description\", keep=\"first\")\n",
    "df.loc[idx,:].sort_values(\"description\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nettoyer la description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Je vais maintenant nettoyer la colonne description, ce qui consiste à analyser le nombre original de token (mots) et de les réduire au maximum tout en conservant la pertinence des mots. C'est à dire retirer les mots unique, retirer les mots qui ne sont pas anglais, ...\n",
    "\n",
    "En nettoyant cette colonne, je vais pouvoir réduire le bruit et étudier au mieux la faisabilité de classification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Je commence d'abord par créer mon corpus, le document qui va contenir toutes les description de tous les produits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# HELPERS\n",
    "\n",
    "import os, sys, time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer, PorterStemmer\n",
    "from nltk.tokenize import word_tokenize, wordpunct_tokenize\n",
    "\n",
    "from nltk.corpus import words, stopwords\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "\n",
    "from wordcloud import WordCloud\n",
    "from PIL import Image\n",
    "from collections import Counter  \n",
    "\n",
    "from pandarallel import pandarallel\n",
    "\n",
    "# ---- \n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer  \n",
    "from sklearn.decomposition import PCA  \n",
    "from sklearn.manifold import TSNE  \n",
    "from sklearn.metrics import adjusted_rand_score\n",
    "from sklearn.cluster import KMeans  \n",
    "from umap import UMAP  \n",
    "from sklearn.cluster import DBSCAN  \n",
    "from sklearn.decomposition import TruncatedSVD  \n",
    "from sklearn.decomposition import LatentDirichletAllocation  \n",
    "from sklearn.metrics import accuracy_score  \n",
    "from sklearn.metrics import confusion_matrix  \n",
    "from gensim.models import Word2Vec  \n",
    "\n",
    "# nltk.download(\"omw-1.4\")\n",
    "# nltk.download(\"wordnet\")\n",
    "# nltk.download(\"stopwords\")\n",
    "# nltk.download(\"words\")\n",
    "\n",
    "max_workers = os.cpu_count()  \n",
    "print(\"Maximum number of workers:\", max_workers)  \n",
    "\n",
    "pandarallel.initialize(progress_bar=True, nb_workers=max_workers)\n",
    "\n",
    "sns.set()\n",
    "\n",
    "# Display the number of tokens and unique\n",
    "def display_token_info(tokens):\n",
    "    print(f\"nb tokens {len(tokens)}, nb token uniques {len(set(tokens))}\")\n",
    "    print(tokens[:30])\n",
    "    \n",
    "english_stop_words = set(stopwords.words(\"english\"))\n",
    "\n",
    "\n",
    "def process_text_step_1(doc):\n",
    "    \"\"\"\n",
    "    required arguments:\n",
    "    -------------------\n",
    "    \n",
    "    doc: str : the document to process\n",
    "    \n",
    "    return:\n",
    "    -------------------\n",
    "    \n",
    "    a list of tokens\n",
    "    \"\"\"\n",
    "    \n",
    "    # Reduce to lowercase\n",
    "    doc = doc.lower().strip()\n",
    "    \n",
    "    tokenizer = RegexpTokenizer(r\"\\w+\")\n",
    "    raw_tokens_list = tokenizer.tokenize(doc)\n",
    "    \n",
    "    # Remove stop words\n",
    "    # clean_tokens_list = [w for w in raw_tokens_list if w not in english_stop_words]\n",
    "    \n",
    "    return raw_tokens_list\n",
    "\n",
    "def process_text_step_2(doc, stopwords):\n",
    "    \"\"\"\n",
    "    required arguments:\n",
    "    -------------------\n",
    "    \n",
    "    doc: str : the document to process\n",
    "    stopwords: list : a list of stopwords to remove from the token\n",
    "    \n",
    "    return:\n",
    "    -------------------\n",
    "    \n",
    "    a list of tokens\n",
    "    \"\"\"\n",
    "    processed_tokens = process_text_step_1(doc)\n",
    "    \n",
    "    # Remove stop words\n",
    "    processed_tokens = [w for w in processed_tokens if w not in stopwords]\n",
    "    \n",
    "    return processed_tokens\n",
    "\n",
    "def process_text_step_3(doc, stopwords):\n",
    "    \"\"\"\n",
    "    required arguments:\n",
    "    -------------------\n",
    "    \n",
    "    doc: str : the document to process\n",
    "    stopwords: list : a list of stopwords to remove from the token\n",
    "    \n",
    "    return:\n",
    "    -------------------\n",
    "    \n",
    "    a list of tokens\n",
    "    \"\"\"\n",
    "    processed_tokens = process_text_step_2(doc, stopwords)\n",
    "    \n",
    "    processed_tokens = [w for w in processed_tokens if w.isalpha()]\n",
    "    \n",
    "    return processed_tokens\n",
    "\n",
    "def process_text_step_4(doc, \n",
    "                        stopwords, \n",
    "                        delete_words\n",
    "                        ):\n",
    "    \"\"\"\n",
    "    required arguments:\n",
    "    -------------------\n",
    "    \n",
    "    doc: str : the document to process\n",
    "    stopwords: list : a list of stopwords to remove from the token\n",
    "    delete_words: list : a list of words to remove from the token\n",
    "    \n",
    "    return:\n",
    "    -------------------\n",
    "    \n",
    "    a list of tokens\n",
    "    \"\"\"\n",
    "    processed_tokens = process_text_step_3(doc, stopwords)\n",
    "    processed_tokens = [w for w in processed_tokens if w not in delete_words]\n",
    "    \n",
    "    return processed_tokens\n",
    "\n",
    "def process_text_step_5(doc, \n",
    "                        stopwords, \n",
    "                        delete_words,\n",
    "                        min_word_length\n",
    "                        ):\n",
    "    \"\"\"\n",
    "    required arguments:\n",
    "    -------------------\n",
    "    \n",
    "    doc: str : the document to process\n",
    "    stopwords: list : a list of stopwords to remove from the token\n",
    "    delete_words: list : a list of words to remove from the token\n",
    "    min_word_length: int : a minimum number of characters per word to keep\n",
    "    \n",
    "    return:\n",
    "    -------------------\n",
    "    \n",
    "    a list of tokens\n",
    "    \"\"\"\n",
    "    processed_tokens = process_text_step_4(doc, stopwords, delete_words)\n",
    "    processed_tokens = [w for w in processed_tokens if len(w) >= min_word_length]\n",
    "\n",
    "    return processed_tokens\n",
    "\n",
    "def process_text_step_6(doc, \n",
    "                        stopwords, \n",
    "                        delete_words,\n",
    "                        min_word_length,\n",
    "                        use_lemm,\n",
    "                        ):\n",
    "    \"\"\"\n",
    "    required arguments:\n",
    "    -------------------\n",
    "    \n",
    "    doc: str : the document to process\n",
    "    stopwords: list : a list of stopwords to remove from the token\n",
    "    delete_words: list : a list of words to remove from the token\n",
    "    min_word_length: int : a minimum number of characters per word to keep\n",
    "    use_lemm: bool : define if it uses lemmatizer, if false, it will defined stemmer\n",
    "    \n",
    "    return:\n",
    "    -------------------\n",
    "    \n",
    "    a list of tokens\n",
    "    \"\"\"\n",
    "    processed_tokens = process_text_step_5(doc, stopwords, delete_words, min_word_length)\n",
    "\n",
    "    if use_lemm:\n",
    "         trans = WordNetLemmatizer()\n",
    "         processed_tokens = [trans.lemmatize(i) for i in processed_tokens]\n",
    "    else:\n",
    "        trans = PorterStemmer()\n",
    "        processed_tokens = [trans.stem(i) for i in processed_tokens]\n",
    "\n",
    "    # Could improve this by reordering step, not needed for now\n",
    "    # Once again, I remove all tokens >= min_word_length\n",
    "    processed_tokens = [w for w in processed_tokens if len(w) >= min_word_length]\n",
    "    # Once again, I remove all delete_words\n",
    "    processed_tokens = [w for w in processed_tokens if w not in delete_words]\n",
    "\n",
    "    return processed_tokens\n",
    "\n",
    "def final_process(doc, \n",
    "                        stopwords, \n",
    "                        delete_words,\n",
    "                        min_word_length,\n",
    "                        use_lemm,\n",
    "                        ):\n",
    "    \"\"\"\n",
    "    required arguments:\n",
    "    -------------------\n",
    "    \n",
    "    doc: str : the document to process\n",
    "    stopwords: list : a list of stopwords to remove from the token\n",
    "    delete_words: list : a list of words to remove from the token\n",
    "    min_word_length: int : a minimum number of characters per word to keep\n",
    "    use_lemm: bool : define if it uses lemmatizer, if false, it will defined stemmer\n",
    "    \n",
    "    return:\n",
    "    -------------------\n",
    "    \n",
    "    a str of joined token\n",
    "    \"\"\"\n",
    "    processed_tokens = process_text_step_6(doc, stopwords, delete_words, min_word_length, use_lemm)\n",
    "\n",
    "    if use_lemm:\n",
    "         trans = WordNetLemmatizer()\n",
    "         processed_tokens = [trans.lemmatize(i) for i in processed_tokens]\n",
    "    else:\n",
    "        trans = PorterStemmer()\n",
    "        processed_tokens = [trans.stem(i) for i in processed_tokens]\n",
    "\n",
    "    # Could improve this by reordering step, not needed for now\n",
    "    # Once again, I remove all tokens >= min_word_length\n",
    "    processed_tokens = [w for w in processed_tokens if len(w) >= min_word_length]\n",
    "    # Once again, I remove all delete_words\n",
    "    processed_tokens = [w for w in processed_tokens if w not in delete_words]\n",
    "\n",
    "    return \" \".join(processed_tokens)\n",
    "\n",
    "def process_text_step_7_deprecated(doc, \n",
    "                        stopwords, \n",
    "                        delete_words,\n",
    "                        min_word_length,\n",
    "                        use_lemm,\n",
    "                        allow_words,\n",
    "                        ):\n",
    "    \"\"\"\n",
    "    required arguments:\n",
    "    -------------------\n",
    "    \n",
    "    doc: str : the document to process\n",
    "    stopwords: list : a list of stopwords to remove from the token\n",
    "    delete_words: list : a list of words to remove from the token\n",
    "    min_word_length: int : a minimum number of characters per word to keep\n",
    "    use_lemm: bool : define if it uses lemmatizer, if false, it will defined stemmer\n",
    "    include_words: list : a list of words to allow to keep\n",
    "    \n",
    "    return:\n",
    "    -------------------\n",
    "    \n",
    "    a list of tokens\n",
    "    \"\"\"\n",
    "    processed_tokens = process_text_step_6(doc, stopwords, delete_words, min_word_length, use_lemm)\n",
    "    processed_tokens = [i for i in processed_tokens if i in allow_words]\n",
    "    return processed_tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_corpus = \" \".join(df[\"description\"].values)\n",
    "raw_corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "J'observe le nombre de charactères"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(raw_corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Première analyse:**\n",
    "- Je tokenize mon document en conservant les caractères alphanumérique et en mettant chaque mot en minuscule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = process_text_step_1(raw_corpus)\n",
    "display_token_info(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "J'ai donc un nombre de token initial de 81,219 token et 6,284 unique.  \n",
    "Je vais tenter de réduire se nombre au maximum par itération.  \n",
    "\n",
    "Je souhaite retirer tous les mots qui sont considérés comme stopwords en Anglais, des mots qui ne seront pas utile à définir une catégorie (le, la, les, ...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Deuxième analyse:**\n",
    "- Je tokenize mon document en conservant les caractères alphanumérique et en mettant chaque mot en minuscule\n",
    "- Je supprime les token qui comprennent les stopwords Anglais."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = process_text_step_2(raw_corpus, english_stop_words)\n",
    "display_token_info(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Déjà ~20k tokens retiré, c'est que le début"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maintenant je souhaite retirer toutes les valeurs qui sont des nombres, je ne pense pas que les valeurs numériques me permettent de mieux distinguer une catégorie."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Troisième analyse:**\n",
    "- Je tokenize mon document en conservant les caractères alphanumérique et en mettant chaque mot en minuscule\n",
    "- Je supprime les token qui comprennent les stopwords Anglais.\n",
    "- Je supprime tous les mots numériques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = process_text_step_3(raw_corpus, english_stop_words)\n",
    "display_token_info(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6k tokens de réduit donc 1k token uniques.  \n",
    "Maintenant, je pense que tous les mots présent uniquement une seul fois dans le corpus ne sont pas utiles pour déterminer une catégorie, je vais donc les supprimer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(tokens).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tokens = pd.Series(tokens).value_counts()\n",
    "tokens_one_occurence = all_tokens[all_tokens==1]\n",
    "tokens_one_occurence = list(tokens_one_occurence.index)\n",
    "\n",
    "print(\"len\",len(tokens_one_occurence))\n",
    "tokens_one_occurence[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Quatrième analyse:**\n",
    "- Je tokenize mon document en conservant les caractères alphanumérique et en mettant chaque mot en minuscule\n",
    "- Je supprime les token qui comprennent les stopwords Anglais.\n",
    "- Je supprime tous les mots numériques\n",
    "- Je supprime tous les mots qui sont présent qu'une seul fois\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = process_text_step_4(raw_corpus, english_stop_words, delete_words=tokens_one_occurence)\n",
    "display_token_info(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "~1500 tokens unique retiré. Je continue.  \n",
    "Je vais observer tous les mots qui ont moins de 3 caractères, je ne suis pas sur que ces mots définissent une catégorie facilement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rien d'interessant a vue d'oeil.  \n",
    "Je les supprime."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Cinquième analyse:**\n",
    "- Je tokenize mon document en conservant les caractères alphanumérique et en mettant chaque mot en minuscule\n",
    "- Je supprime les token qui comprennent les stopwords Anglais.\n",
    "- Je supprime tous les mots numériques\n",
    "- Je supprime tous les mots qui sont présent qu'une seul fois\n",
    "- Je supprime tous les mots qui font moins de 3 caractères\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = process_text_step_5(raw_corpus, english_stop_words, delete_words=tokens_one_occurence, min_word_length=3)\n",
    "display_token_info(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pas beaucoup de tokens retirés, c'est mieux que rien.  \n",
    "Maintenant le plus intéressant, stemmer ou lemmatizer ?\n",
    "\n",
    "- Stemmer: réduit les mots à leur racine (supprime les affixes) (rapide et ne tient pas en compte le contexte)\n",
    "- Lemmatizer: Normalize les mots depuis un dictionnaire (lent et tient en compte le sens des mots)\n",
    "\n",
    "Ici, je souhaite classifier une catégorie, je ne pense pas que le sens des mots soit important comparé à une analyse de positivité d'un text.  \n",
    "Je pense utiliser celui qui me supprimera le plus de token. Je pourrais aussi retenter mon approche plus bas avec l'autre méthode."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sixième analyse:**\n",
    "- Je tokenize mon document en conservant les caractères alphanumérique et en mettant chaque mot en minuscule\n",
    "- Je supprime les token qui comprennent les stopwords Anglais.\n",
    "- Je supprime tous les mots numériques\n",
    "- Je supprime tous les mots qui sont présent qu'une seul fois\n",
    "- Je supprime tous les mots qui font moins de 3 caractères\n",
    "- J'effectue un Stemmer ou Lemmatizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = process_text_step_6(raw_corpus, \n",
    "                             english_stop_words, \n",
    "                             delete_words=tokens_one_occurence, \n",
    "                             min_word_length=3,\n",
    "                             use_lemm=True)\n",
    "display_token_info(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = process_text_step_6(raw_corpus, \n",
    "                             english_stop_words, \n",
    "                             delete_words=tokens_one_occurence, \n",
    "                             min_word_length=3,\n",
    "                             use_lemm=False)\n",
    "display_token_info(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plus rapide et moins de token par stemmer, je vais donc utiliser cette méthode par la suite.  \n",
    "Ça commence à être pas trop mal. \n",
    "\n",
    "Je vais maintenant tester de retirer tous les mots qui ne sont pas dans la langue anglaise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eng_words = [i.lower() for i in words.words()]\n",
    "len(set(eng_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = process_text_step_7_deprecated(raw_corpus, \n",
    "                             english_stop_words, \n",
    "                             delete_words=tokens_one_occurence, \n",
    "                             min_word_length=3,\n",
    "                             use_lemm=False,\n",
    "                             allow_words=eng_words)\n",
    "display_token_info(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Je suis pas fan, j'ai peur de retirer trop de mots. Je perds \"featur\", même si je modifie le step 7 pour ne pas faire de stemmer, je perds également le mot \"feature\".  \n",
    "Je n'ai pas confiance en cette méthode, je ne l'utiliserai pas.\n",
    "\n",
    "C'est déjà pas mal, je vais observer les mots les plus courant pour chaque catégorie puis vérifier si il y a des doublons entre toute les catégories et supprimer ce que je trouve inutile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_per_cat={}\n",
    "for idx, cat in enumerate(df[\"cat\"].unique()):\n",
    "    df_cat = df[df['cat'] == cat]\n",
    "    cat_corpus = \" \".join(df_cat[\"description\"])\n",
    "    \n",
    "    tokens_per_cat[cat] = process_text_step_6(cat_corpus, \n",
    "                             english_stop_words, \n",
    "                             delete_words=tokens_one_occurence, \n",
    "                             min_word_length=3,\n",
    "                             use_lemm=False)\n",
    "    \n",
    "    print(f\"{cat} has {len(cat_corpus)} characters for {len(tokens_per_cat[cat])} words\")\n",
    "    word_frequencies = Counter(tokens_per_cat[cat])  \n",
    "\n",
    "    wordcloud = WordCloud(background_color=\"white\",\n",
    "                      stopwords=[],\n",
    "                      max_words=50).generate_from_frequencies(frequencies=word_frequencies)\n",
    "\n",
    "    plt.imshow(wordcloud)\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_keys = list(tokens_per_cat.keys())  \n",
    "  \n",
    "lengths = [len(tokens_per_cat[key]) for key in category_keys]  \n",
    "df_cat = pd.DataFrame({\"Category\": category_keys, \"Length\": lengths})  \n",
    "df_cat = df_cat.sort_values(by=\"Length\", ascending=False)  \n",
    "  \n",
    "color_palette = sns.color_palette(\"Set3\")  \n",
    "sns.set(style=\"whitegrid\")  \n",
    "sns.barplot(x=\"Category\", y=\"Length\", data=df_cat, palette=color_palette)  \n",
    "plt.xticks(rotation=90)  # Rotate x-axis labels if necessary  \n",
    "plt.xlabel(\"Category\")  \n",
    "plt.ylabel(\"Length\")  \n",
    "plt.title(\"Category Lengths\")  \n",
    "plt.show()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = list(tokens_per_cat.keys())  \n",
    "duplicated_values = []  \n",
    "  \n",
    "for value in pd.Series(tokens_per_cat[categories[0]]).value_counts().index:  \n",
    "    if all(value in pd.Series(tokens_per_cat[cat]).values for cat in categories[1:]):  \n",
    "        duplicated_values.append(value)\n",
    "  \n",
    "print(len(duplicated_values))  \n",
    "print(duplicated_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "J'ai 79 mots en doublons dans toutes les catégories. Ça me rajoutera du bruit, je préfère les retirer.  \n",
    "Pour rappel, le résultat précédent que je conserve est: `nb tokens 51097, nb token uniques 3123`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_deleted_manually = []\n",
    "# words_deleted_manually = [\"com\",\"guarante\",\"best\",\"onlin\",\"warranti\",\"print\"]\n",
    "new_delete_words = list(set(tokens_one_occurence + duplicated_values + words_deleted_manually))\n",
    "tokens = process_text_step_6(raw_corpus, \n",
    "                             english_stop_words, \n",
    "                             delete_words=new_delete_words, \n",
    "                             min_word_length=3,\n",
    "                             use_lemm=True)\n",
    "display_token_info(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Beaucoup de mots retirés mais je suis confiant que c'est utile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_per_cat[cat]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_per_cat={}\n",
    "for idx, cat in enumerate(df[\"cat\"].unique()):\n",
    "    df_cat = df[df['cat'] == cat]\n",
    "    cat_corpus = \" \".join(df_cat[\"description\"])\n",
    "    \n",
    "    tokens_per_cat[cat] = process_text_step_6(cat_corpus, \n",
    "                             english_stop_words, \n",
    "                             delete_words=new_delete_words, \n",
    "                             min_word_length=3,\n",
    "                             use_lemm=False)\n",
    "    \n",
    "    print(f\"{cat} has {len(cat_corpus)} characters for {len(tokens_per_cat[cat])} words\")\n",
    "    word_frequencies = Counter(tokens_per_cat[cat])  \n",
    "\n",
    "    wordcloud = WordCloud(background_color=\"white\",\n",
    "                      stopwords=[],\n",
    "                      max_words=50).generate_from_frequencies(frequencies=word_frequencies)\n",
    "\n",
    "    plt.imshow(wordcloud)\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Je suis satisfait de ce nettoyage.\n",
    "\n",
    "Pour rappel, step initial: `nb tokens 81219, nb token uniques 6284`  \n",
    "maintenant: `nb tokens 39942, nb token uniques 3030`\n",
    "\n",
    "Réduction de plus de 50%.\n",
    "Je vais donc lancer cette transormation sur toutes les lignes de mon dataframe et rajouter une colonne \"description_clean\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean_lemm = df.copy()\n",
    "df_clean_stemm = df.copy()\n",
    "\n",
    "df_clean_stemm[\"clean_desc\"] = df_clean_stemm[\"description\"].parallel_apply(lambda x: final_process(x, \n",
    "                             english_stop_words, \n",
    "                             delete_words=new_delete_words, \n",
    "                             min_word_length=3,\n",
    "                             use_lemm=False))\n",
    "\n",
    "df_clean_lemm[\"clean_desc\"] = df_clean_lemm[\"description\"].parallel_apply(lambda x: final_process(x, \n",
    "                             english_stop_words, \n",
    "                             delete_words=new_delete_words, \n",
    "                             min_word_length=3,\n",
    "                             use_lemm=False))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### BONUS FOR TESTING\n",
    "df_clean = df.copy()\n",
    "df_clean[\"clean_desc_step1\"] = df_clean_stemm[\"description\"].parallel_apply(lambda x: \" \".join(process_text_step_1(x)))\n",
    "\n",
    "df_clean[\"clean_desc_step2\"] = df_clean_stemm[\"description\"].parallel_apply(lambda x: \" \".join(process_text_step_2(x, \n",
    "                             english_stop_words)))\n",
    "\n",
    "df_clean[\"clean_desc_step3\"] = df_clean_stemm[\"description\"].parallel_apply(lambda x: \" \".join(process_text_step_3(x, \n",
    "                             english_stop_words)))\n",
    "\n",
    "df_clean[\"clean_desc_step4\"] = df_clean_stemm[\"description\"].parallel_apply(lambda x: \" \".join(process_text_step_4(x, \n",
    "                             english_stop_words, \n",
    "                             delete_words=new_delete_words)))\n",
    "\n",
    "df_clean[\"clean_desc_step5\"] = df_clean_stemm[\"description\"].parallel_apply(lambda x: \" \".join(process_text_step_5(x, \n",
    "                             english_stop_words, \n",
    "                             delete_words=new_delete_words, \n",
    "                             min_word_length=3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "J'affiche la colonne description orginal et celle nettoyé pour les comparés"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', -1)  \n",
    "df_clean_stemm[[\"description\",\"clean_desc\"]].head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df[df[\"clean_desc\"].isna()][\"description\"]\n",
    "df_clean_stemm[df_clean_stemm[\"clean_desc\"] == \"\"]\n",
    "# df = df.drop(df[df[\"clean_desc\"] == \"\"].index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Je sauvegarde mon dataframe dans un csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean_stemm.to_csv(\"./../input/df_cleaned_stemm.csv\", index=False)\n",
    "df_clean_lemm.to_csv(\"./../input/df_cleaned_lemm.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "À noter, je n'ai pas utiliser de bi-grams ou tri-grams car dans une première réflexion, je ne pense pas que c'est utile pour classifier des catégories.\n",
    "\n",
    "Néamoins, pour valider cette approche, je le ferais tout de même par la suite pour observer la différence de précision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, item in df_clean_stemm.iterrows():\n",
    "    desc = item[\"clean_desc\"]\n",
    "    words = desc.split(\" \")  \n",
    "    \n",
    "    df_clean_stemm.at[idx, 'word_count_clean'] = len(words)  \n",
    "    df_clean_stemm.at[idx, 'unique_word_count_clean'] = len(set(words))\n",
    "    \n",
    "for idx, item in df_clean_lemm.iterrows():\n",
    "    desc = item[\"clean_desc\"]\n",
    "    words = desc.split(\" \")  \n",
    "    \n",
    "    df_clean_lemm.at[idx, 'word_count_clean'] = len(words)  \n",
    "    df_clean_lemm.at[idx, 'unique_word_count_clean'] = len(set(words)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_df_clean = df_clean_stemm.sort_values(\"word_count_clean\", ascending=False)    \n",
    "top_names = sorted_df_clean[\"product_name\"].head(20)  \n",
    "  \n",
    "top_word_counts = sorted_df_clean[\"word_count_clean\"].head(20)  \n",
    "top_unique_counts = sorted_df_clean[\"unique_word_count_clean\"].head(20)  \n",
    "\n",
    "plt.figure(figsize=(15, 10))  \n",
    "plt.subplot(2, 1, 1)\n",
    "\n",
    "# Create a horizontal barplot using seaborn    \n",
    "sns.barplot(y=top_names, x=top_word_counts, orient=\"h\",  color=\"#e7a44a\", label=\"Word Count\")    \n",
    "sns.barplot(y=top_names, x=top_unique_counts, orient=\"h\",  color=\"#313c59\", label=\"Unique Word Count\")    \n",
    "\n",
    "# Set the title and axes labels    \n",
    "plt.title(\"Top 20 Names by Word Count (STEMM)\")    \n",
    "plt.xlabel(\"Word Count\")    \n",
    "plt.ylabel(\"Name\")    \n",
    "\n",
    "# Rotate x-axis labels for better readability    \n",
    "plt.xticks(rotation=90)\n",
    "    \n",
    "plt.subplot(2, 1, 2)\n",
    "sorted_df_clean = df_clean_lemm.sort_values(\"word_count_clean\", ascending=False)    \n",
    "top_names = sorted_df_clean[\"product_name\"].head(20)  \n",
    "  \n",
    "top_word_counts = sorted_df_clean[\"word_count_clean\"].head(20)  \n",
    "top_unique_counts = sorted_df_clean[\"unique_word_count_clean\"].head(20)  \n",
    "\n",
    "# Create a horizontal barplot using seaborn    \n",
    "sns.barplot(y=top_names, x=top_word_counts, orient=\"h\",  color=\"#e7a44a\", label=\"Word Count\")    \n",
    "sns.barplot(y=top_names, x=top_unique_counts, orient=\"h\",  color=\"#313c59\", label=\"Unique Word Count\")    \n",
    "\n",
    "# Set the title and axes labels    \n",
    "plt.title(\"Top 20 Names by Word Count (LEMM)\")    \n",
    "plt.xlabel(\"Word Count\")    \n",
    "plt.ylabel(\"Name\")    \n",
    "\n",
    "# Rotate x-axis labels for better readability    \n",
    "plt.xticks(rotation=90)\n",
    "\n",
    "# Display the plot \n",
    "plt.legend()\n",
    "plt.tight_layout()  \n",
    "plt.show()  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification text non supervisé & supervisé"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Étapes:\n",
    "- **Non supervisé**\n",
    "  - Extraction des features\n",
    "  - Réduction en 2 dimensions\n",
    "  - Kmeans\n",
    "  - Visualisation Graphique\n",
    "  - Score\n",
    "\n",
    "- **Supervisé**\n",
    "  - Extraction des features\n",
    "  - Réduction en 2 dimensions\n",
    "  - Classification avec apprentissage\n",
    "  - Visualisation Graphique\n",
    "  - Score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertModel  \n",
    "import tensorflow as tf  \n",
    "import tensorflow_hub as hub  \n",
    "from sklearn.model_selection import train_test_split  \n",
    "from sklearn.ensemble import RandomForestClassifier  \n",
    "\n",
    "def plot_confusion_matrix(y_true, y_pred, labels, title):  \n",
    "    \"\"\"  \n",
    "    Plots the confusion matrix for clustering results.  \n",
    "    \"\"\"  \n",
    "    cm = confusion_matrix(y_true, y_pred)  \n",
    "    sns.heatmap(cm, annot=True, fmt='d', xticklabels=labels, yticklabels=labels)  \n",
    "    plt.xlabel('Predicted')  \n",
    "    plt.ylabel('True')  \n",
    "    plt.title(f\"Confusion matrix {title}\")\n",
    "  \n",
    "# Plot the confusion matrix  \n",
    "# labels = np.unique(test_df['orginal_cat'])  # Unique labels in target labels  \n",
    "# plot_confusion_matrix(test_df['orginal_cat'], test_df['predicted_cat'], labels)  \n",
    "\n",
    "\n",
    "def modify_labels(y_true, y_pred):  \n",
    "    \"\"\"  \n",
    "    Modifies the predicted values based on the confusion matrix.  \n",
    "    \"\"\"  \n",
    "    cm = confusion_matrix(y_true, y_pred)  \n",
    "    n_classes = len(np.unique(y_true))  \n",
    "    modified_pred = np.copy(y_pred)\n",
    "    \n",
    "    mapping = {}\n",
    "    for true_label in range(n_classes): \n",
    "        max_count = -1  \n",
    "        for pred_label in range(n_classes):\n",
    "            if cm[true_label, pred_label] > max_count and pred_label not in mapping.values():  \n",
    "                max_count = cm[true_label, pred_label]\n",
    "                mapping[true_label] = pred_label\n",
    "        \n",
    "        # print(mapping)\n",
    "        # # print(mapping)\n",
    "        # print(f\"Replace y_pred {mapping[true_label]} by {true_label}, because {max_count}\")\n",
    "        # print()\n",
    "    for true_label, pred_label in mapping.items():  \n",
    "         modified_pred[y_pred == pred_label] = true_label\n",
    "        \n",
    "    return modified_pred\n",
    "  \n",
    "# # Modify the predicted values based on the confusion matrix  \n",
    "# test_df['predicted_cat_adjusted'] = modify_labels(test_df['orginal_cat'], test_df['predicted_cat'])\n",
    "# plot_confusion_matrix(test_df['orginal_cat'], test_df['predicted_cat_adjusted'], labels)  \n",
    "\n",
    "def check_performance(df, \n",
    "                      reduction_name, \n",
    "                      reduction_method,\n",
    "                      \n",
    "                      clustering_name,\n",
    "                      clustering_method,\n",
    "                      \n",
    "                      original_df,\n",
    "                      draw_graph=False):\n",
    "    \n",
    "    # Apply a dimensional reduction  \n",
    "    reduced_data = reduction_method.fit_transform(df)  \n",
    "\n",
    "    # Determine new clusters  \n",
    "    # kmeans = KMeans(n_clusters=7, n_init=10) # Change the number of clusters based on your data  \n",
    "    clusters = clustering_method.fit_predict(reduced_data)\n",
    "\n",
    "    # clusters_adjusted = clusters\n",
    "    clusters_adjusted = modify_labels(original_df['cat_e'], clusters)\n",
    "    # Print the ARI score  \n",
    "    ari_score = adjusted_rand_score(original_df['cat_e'], clusters)\n",
    "    accuracy = accuracy_score(original_df['cat_e'], clusters)  \n",
    "    \n",
    "    accuracy_adjusted = accuracy_score(original_df['cat_e'], clusters_adjusted)  \n",
    "    \n",
    "    if(draw_graph):\n",
    "        print(f\"ARI Score ({clustering_name} - {reduction_name}) : %.2f\" % ari_score)  \n",
    "        print(f\"ACCURACY ({clustering_name} - {reduction_name}) : %.2f\" % accuracy)  \n",
    "        print(f\"ACCURACY Adjusted ({clustering_name} - {reduction_name}) : %.2f\" % accuracy_adjusted)  \n",
    "        \n",
    "        # Plot on the left the datapoints with existing categories  \n",
    "        plt.figure(figsize=(12, 3))  \n",
    "        plt.subplot(1, 2, 1)  \n",
    "        sns.scatterplot(x=reduced_data[:, 0], y=reduced_data[:, 1], hue=original_df['cat'], palette='Set1')  \n",
    "        plt.title(f\"Real Categories {clustering_name} - {reduction_name}\")  \n",
    "        plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)  \n",
    "        \n",
    "        # Plot on the right the datapoints with determined categories  \n",
    "        plt.subplot(1, 2, 2)  \n",
    "        sns.scatterplot(x=reduced_data[:, 0], y=reduced_data[:, 1], hue=clusters, palette='Set1')  \n",
    "        plt.title(f\"Predicted Categories {clustering_name} - {reduction_name}\")  \n",
    "        plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)  \n",
    "    \n",
    "        plt.tight_layout()  \n",
    "        plt.show()\n",
    "        \n",
    "        plt.figure(figsize=(12, 3))\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plot_confusion_matrix(original_df['cat_e'], clusters, np.unique(original_df['cat_e']), \"Predicted\")\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plot_confusion_matrix(original_df['cat_e'], clusters_adjusted, np.unique(original_df['cat_e']), \"Predicted and adjusted\")\n",
    "        plt.tight_layout()  \n",
    "        plt.show()\n",
    "    \n",
    "    \n",
    "    return {\"label\": f\"{reduction_name}\", \"ari_score\": ari_score,\"accuracy\": accuracy_adjusted, \"clusters\": clusters}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kmeans = KMeans(n_clusters=7, n_init=10, init='k-means++', max_iter=300, random_state=23)\n",
    "# tsne = PCA(n_components=2)\n",
    "# test_res = check_performance(tfidf_df, \n",
    "#                             \"tsne\", \n",
    "#                             tsne, \n",
    "#                             \"kmeans\", \n",
    "#                             kmeans, \n",
    "#                             df,\n",
    "#                             draw_graph=True)\n",
    "# kmeans = KMeans(n_clusters=7, n_init=10, init='k-means++', max_iter=300, random_state=23)\n",
    "# tsne = TSNE(n_components=2, random_state=23)\n",
    "# test_res = check_performance(tfidf_df, \n",
    "#                             \"tsne\", \n",
    "#                             tsne, \n",
    "#                             \"kmeans\", \n",
    "#                             kmeans, \n",
    "#                             df,\n",
    "#                             draw_graph=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusterings = [\n",
    "    {\"name\": \"KMEANS\", \"model\": KMeans(n_clusters=7, n_init=10, init='k-means++', max_iter=300, random_state=42)},\n",
    "    # {\"name\": \"DBSCAN\", \"model\": DBSCAN(eps=0.5, min_samples=5)  }\n",
    "]\n",
    "\n",
    "dimension_reduction = [\n",
    "    {\"name\": \"PCA\", \"model\": PCA(n_components=2)},\n",
    "    {\"name\": \"t-SNE\", \"model\": TSNE(n_components=2, perplexity=40, random_state=42)  },\n",
    "    {\"name\": \"UMAP\", \"model\": UMAP(n_components=2) },\n",
    "    {\"name\": \"SVD\", \"model\": TruncatedSVD(n_components=2) },\n",
    "]\n",
    "\n",
    "\n",
    "def check_one_df(dataFrame, draw_graph=False):\n",
    "    \n",
    "    df_scores = pd.DataFrame(columns=[\"label\", \"ari\", \"accuracy\"])  \n",
    "\n",
    "    for idx, dim_reduc in enumerate(dimension_reduction):\n",
    "        for idx2, clustering in enumerate(clusterings):\n",
    "            res = check_performance(dataFrame, \n",
    "                            dim_reduc[\"name\"], \n",
    "                            dim_reduc[\"model\"], \n",
    "                            clustering[\"name\"], \n",
    "                            clustering[\"model\"], \n",
    "                            df,\n",
    "                            draw_graph)\n",
    "            row = pd.DataFrame({\"label\": res[\"label\"], \"ari\": res[\"ari_score\"], \"accuracy\": res[\"accuracy\"]}, index=[0])\n",
    "            df_scores = pd.concat([df_scores, row], ignore_index=True)\n",
    "            \n",
    "    return df_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CountVectorizer\n",
    "count_vectorizer = CountVectorizer()  \n",
    "bow_matrix = count_vectorizer.fit_transform(df_clean_stemm['clean_desc'])  \n",
    "bow_df = pd.DataFrame(bow_matrix.toarray(), columns=count_vectorizer.get_feature_names_out())   \n",
    "bow_df_scores = check_one_df(bow_df,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean_lemm['clean_desc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF-IDF method  \n",
    "tfidf_vectorizer = TfidfVectorizer()  \n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(df_clean_lemm['clean_desc'])  \n",
    "tfidf_df = pd.DataFrame(tfidf_matrix.toarray(), columns=tfidf_vectorizer.get_feature_names_out())\n",
    "\n",
    "tfidf_df_scores = check_one_df(tfidf_df, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Will be redefined later on\n",
    "def check_one_df_supervised():\n",
    "    return np.nan\n",
    "\n",
    "def get_score_bert(texts, supervised=False):  \n",
    "    # Load pre-trained BERT model & tokenizer  \n",
    "    tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')  \n",
    "    model = BertModel.from_pretrained('bert-base-uncased')  \n",
    "      \n",
    "    bert_embeddings = []  \n",
    "      \n",
    "    for desc in texts:  \n",
    "        # Encode the descriptions using BERT tokenizer  \n",
    "        inputs = tokenizer(desc, padding=True, truncation=True, return_tensors=\"pt\", max_length=512)  \n",
    "        # Get the output from BERT model  \n",
    "        outputs = model(**inputs)  \n",
    "        # Use the mean of the last hidden states as the document representation  \n",
    "        embeddings = outputs.last_hidden_state.mean(dim=1).detach().numpy()  \n",
    "        bert_embeddings.append(embeddings[0])  \n",
    "          \n",
    "    bert_df = pd.DataFrame(bert_embeddings)\n",
    "    \n",
    "    if(supervised):\n",
    "        return check_one_df_supervised(bert_df, False)\n",
    "    else:\n",
    "        return check_one_df(bert_df, False)\n",
    "\n",
    "def get_score_use(texts, supervised=False):  \n",
    "    # Load pre-trained USE model  \n",
    "    use = hub.load(\"https://www.kaggle.com/models/google/universal-sentence-encoder/frameworks/TensorFlow2/variations/universal-sentence-encoder/versions/2\")  \n",
    "      \n",
    "    use_embeddings = []  \n",
    "      \n",
    "    for desc in texts:  \n",
    "        # Generate embedding for the description  \n",
    "        embeddings = use([desc])  \n",
    "        use_embeddings.append(embeddings.numpy()[0])  \n",
    "  \n",
    "    use_df = pd.DataFrame(use_embeddings)\n",
    "    if(supervised):\n",
    "        return check_one_df_supervised(use_df, False)\n",
    "    else:\n",
    "        return check_one_df(use_df, False)\n",
    "  \n",
    "def get_score_count_vectorizer(texts, supervised=False):\n",
    "    # CountVectorizer\n",
    "    count_vectorizer = CountVectorizer()  \n",
    "    bow_matrix = count_vectorizer.fit_transform(texts)  \n",
    "    df_model = pd.DataFrame(bow_matrix.toarray(), columns=count_vectorizer.get_feature_names_out())\n",
    "    if(supervised):\n",
    "        return check_one_df_supervised(df_model, False)\n",
    "    else:\n",
    "        return check_one_df(df_model, False)\n",
    "    \n",
    "def get_score_tfidf(texts, supervised=False):\n",
    "    # TF-IDF method  \n",
    "    tfidf_vectorizer = TfidfVectorizer()  \n",
    "    tfidf_matrix = tfidf_vectorizer.fit_transform(texts)  \n",
    "    df_model = pd.DataFrame(tfidf_matrix.toarray(), columns=tfidf_vectorizer.get_feature_names_out())\n",
    "    if(supervised):\n",
    "            return check_one_df_supervised(df_model, False)\n",
    "    else:\n",
    "        return check_one_df(df_model, False)    \n",
    "def get_score_word2vec(texts, supervised=False):\n",
    "    sentences = [doc.split() for doc in texts]  \n",
    "    model = Word2Vec(sentences, vector_size=100,\n",
    "                                    window=5,\n",
    "                                    min_count=2)  \n",
    "\n",
    "    word2vec_embeddings = []  \n",
    "    for doc in sentences:  \n",
    "        embeddings = []  \n",
    "        for word in doc:  \n",
    "            if word in model.wv:  \n",
    "                embeddings.append(model.wv[word])  \n",
    "        if len(embeddings) > 0:  \n",
    "            word2vec_embeddings.append(np.mean(embeddings, axis=0))  \n",
    "        else:  \n",
    "            word2vec_embeddings.append(np.zeros(model.vector_size))  \n",
    "    \n",
    "    word2vec_df = pd.DataFrame(word2vec_embeddings)  \n",
    "    if(supervised):\n",
    "            return check_one_df_supervised(word2vec_df, False)\n",
    "    else:\n",
    "        return check_one_df(word2vec_df, False)\n",
    "\n",
    "def calculate_accuracy_from_df(texts, supervised=False):\n",
    "    \n",
    "    scores = [\n",
    "        # Calculate using count vectorizer\n",
    "        {\"name\": \"count-vectorizer\", \"values\": get_score_count_vectorizer(texts,supervised)},  \n",
    "        # Calculate using tf-idf\n",
    "        {\"name\": \"tf-idf\", \"values\": get_score_tfidf(texts,supervised)},  \n",
    "    ]\n",
    "    \n",
    "    if(supervised == False):\n",
    "        # Calculate using Word2Vec\n",
    "        scores.append({\"name\": \"word2vec\", \"values\": get_score_word2vec(texts,supervised)})\n",
    "        \n",
    "        # Calculate using bert\n",
    "        scores.append({\"name\": \"bert\", \"values\": get_score_bert(texts,supervised)}),  \n",
    "        # Calculate using use\n",
    "        scores.append({\"name\": \"use\", \"values\": get_score_use(texts,supervised)}),  \n",
    "        \n",
    "    \n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_score_for_one_df(df_scores):\n",
    "    \n",
    "    combined_df_ari = pd.concat([df['values'].assign(source=df['name']) for df in df_scores])  \n",
    "    combined_df_accuracy = pd.concat([df['values'].assign(source=df['name']) for df in df_scores])  \n",
    "\n",
    "    max_accuracy = combined_df_accuracy[\"accuracy\"].max()\n",
    "    max_accuracy_name = combined_df_accuracy.loc[combined_df_accuracy[\"accuracy\"] == max_accuracy, \"source\"].values[0]  \n",
    "    max_accuracy_label = combined_df_accuracy.loc[combined_df_accuracy[\"accuracy\"] == max_accuracy, \"label\"].values[0]  \n",
    "\n",
    "    max_ari = combined_df_ari[\"ari\"].max()\n",
    "    max_ari_name = combined_df_ari.loc[combined_df_ari[\"ari\"] == max_ari, \"source\"].values[0]  \n",
    "    max_ari_label = combined_df_ari.loc[combined_df_ari[\"ari\"] == max_ari, \"label\"].values[0]  \n",
    "\n",
    "    print(\"Max accuracy\", round(max_accuracy,2), \"from\",max_accuracy_name, \"with\", max_accuracy_label)\n",
    "    print(\"Max ari\", round(max_ari,2), \"from\",max_ari_name, \"with\", max_ari_label)\n",
    "    plt.figure(figsize=(15, 3))  \n",
    "    plt.subplot(1, 2, 1)  \n",
    "    sns.set(style='darkgrid')    \n",
    "    sns.pointplot(x='label', y='ari', hue='source', data=combined_df_ari, palette='colorblind')    \n",
    "    plt.xlabel('Methods')    \n",
    "    plt.ylabel('ARI')    \n",
    "    plt.title('ARI per methods using KMEANS')    \n",
    "    plt.xticks(rotation=45)  \n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)    \n",
    "  \n",
    "    plt.subplot(1, 2, 2)    \n",
    "    sns.pointplot(x='label', y='accuracy', hue='source', data=combined_df_accuracy, palette='colorblind')    \n",
    "    plt.xlabel('Methods')    \n",
    "    plt.ylabel('Accuracy')    \n",
    "    plt.title('Accuracy per methods KMEANS')    \n",
    "    plt.xticks(rotation=45)  \n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)    \n",
    "  \n",
    "    plt.tight_layout()  # Adjust spacing between subplots  \n",
    "    plt.show()  \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scs = calculate_accuracy_from_df(df_clean_lemm[\"clean_desc\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_score_for_one_df(scs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_by_df = [\n",
    "    {\"name\": \"all_with_lemm\", \"scores\": calculate_accuracy_from_df(df_clean_lemm[\"clean_desc\"])},\n",
    "    {\"name\": \"all_with_stemm\", \"scores\": calculate_accuracy_from_df(df_clean_stemm[\"clean_desc\"])},\n",
    "    {\"name\": \"raw\", \"scores\": calculate_accuracy_from_df(df[\"description\"])},\n",
    "    {\"name\": \"step1\", \"scores\": calculate_accuracy_from_df(df_clean[\"clean_desc_step1\"])},\n",
    "    {\"name\": \"step2\", \"scores\": calculate_accuracy_from_df(df_clean[\"clean_desc_step2\"])},\n",
    "    {\"name\": \"step3\", \"scores\": calculate_accuracy_from_df(df_clean[\"clean_desc_step3\"])},\n",
    "    {\"name\": \"step4\", \"scores\": calculate_accuracy_from_df(df_clean[\"clean_desc_step4\"])},\n",
    "    {\"name\": \"step5\", \"scores\": calculate_accuracy_from_df(df_clean[\"clean_desc_step5\"])},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_scores_dfs = pd.DataFrame({\"dataframe\":[], \"feature_extraction\":[], \"reduction_method\": [], \"ari\": [], \"accuracy\":[], \"full_label\":[] })\n",
    "for _, df_item in enumerate(scores_by_df):\n",
    "    for _, global_score in enumerate(df_item[\"scores\"]):\n",
    "        global_score[\"values\"][\"dataframe\"] = df_item[\"name\"]\n",
    "        global_score[\"values\"][\"feature_extraction\"] = global_score[\"name\"]\n",
    "        global_score[\"values\"] = global_score[\"values\"].rename(columns={'label': 'reduction_method'})\n",
    "        global_score[\"values\"][\"full_label\"] = global_score[\"values\"].apply(lambda row: f'{df_item[\"name\"]}-{global_score[\"name\"]}-{row[\"reduction_method\"]}', axis=1)  \n",
    "        full_scores_dfs = pd.concat([full_scores_dfs, global_score[\"values\"]], ignore_index=True)\n",
    "        # for _, score in enumerate(global_score[\"values\"]):\n",
    "        #     # print(f'Label = {score[\"label\"]}')\n",
    "        #     # print(f'Label = {score[\"label\"]}, accuracy = {score[\"accuracy\"]}')\n",
    "        #     print(global_score[\"values\"].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_scores_dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort the dataframe by accuracy in descending order  \n",
    "sorted_df = full_scores_dfs.sort_values(by='accuracy', ascending=False)  \n",
    "  \n",
    "# Select the top 20 records  \n",
    "top_20_df = sorted_df.head(20).reset_index()\n",
    "  \n",
    "# Create the bar plot  \n",
    "plt.figure(figsize=(10, 6))  \n",
    "ax = sns.barplot(data=top_20_df, x='accuracy', y='full_label', orient='h')  \n",
    "plt.xlabel('Accuracy')  \n",
    "plt.ylabel('Full Label')  \n",
    "plt.title('Top 20 by Accuracy')  \n",
    "\n",
    "# Add accuracy scores within each bar  \n",
    "for index, row in top_20_df.iterrows():  \n",
    "    ax.text(0.05, index + 0.2, f\"{row['accuracy']:.3f}\", color='black', ha=\"right\")  \n",
    "  \n",
    "\n",
    "plt.show()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Supervised Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB  \n",
    "from sklearn.svm import SVC \n",
    "\n",
    "clusterings = [\n",
    "    {\"name\": \"RandomForestClassifier\", \"model\": RandomForestClassifier()},\n",
    "    # {\"name\": \"Naive Bayes\", \"model\": MultinomialNB(alpha=1.0)},  \n",
    "    {\"name\": \"Support Vector Machines\", \"model\": SVC(kernel='linear', C=1.0)}  \n",
    "]\n",
    "\n",
    "dimension_reduction = [\n",
    "    {\"name\": \"None\", \"model\": np.nan},\n",
    "    {\"name\": \"PCA\", \"model\": PCA(n_components=2)},\n",
    "    {\"name\": \"t-SNE\", \"model\": TSNE(n_components=2, perplexity=40, random_state=42)  },\n",
    "    {\"name\": \"UMAP\", \"model\": UMAP(n_components=2) },\n",
    "    {\"name\": \"SVD\", \"model\": TruncatedSVD(n_components=2) },\n",
    "]\n",
    "\n",
    "\n",
    "def check_one_df_supervised(dataFrame, draw_graph=False):\n",
    "    \n",
    "    df_scores = pd.DataFrame(columns=[\"label\", \"ari\", \"accuracy\"])  \n",
    "\n",
    "    for idx, dim_reduc in enumerate(dimension_reduction):\n",
    "        for idx2, clustering in enumerate(clusterings):\n",
    "            res = check_performance_supervised(dataFrame, \n",
    "                            dim_reduc[\"name\"], \n",
    "                            dim_reduc[\"model\"], \n",
    "                            clustering[\"name\"], \n",
    "                            clustering[\"model\"], \n",
    "                            df,\n",
    "                            draw_graph)\n",
    "            row = pd.DataFrame({\"label\": res[\"label\"], \"ari\": res[\"ari_score\"], \"model\": res[\"model\"], \"accuracy\": res[\"accuracy\"]}, index=[0])\n",
    "            df_scores = pd.concat([df_scores, row], ignore_index=True)\n",
    "            \n",
    "    return df_scores\n",
    "\n",
    "def check_performance_supervised(df, \n",
    "                      reduction_name,\n",
    "                      reduction_method,\n",
    "                      \n",
    "                      supervised_name,\n",
    "                      supervised_method,\n",
    "                      \n",
    "                      original_df,\n",
    "                      draw_graph=False):\n",
    "    \n",
    "    print(reduction_name, supervised_method, df.shape)\n",
    "    X = df\n",
    "    y = original_df[\"cat_e\"]\n",
    "\n",
    "    if(reduction_name == \"None\"):\n",
    "        X = X\n",
    "    else:\n",
    "        # Apply a dimensional reduction  \n",
    "        X_reduced = reduction_method.fit_transform(df)  \n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "    \n",
    "    supervised_method.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred = supervised_method.predict(X_test)\n",
    "    y_pred_full = supervised_method.predict(X)\n",
    "\n",
    "    # Print the ARI score  \n",
    "    ari_score = adjusted_rand_score(y_test, y_pred)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    # accuracy_adjusted = accuracy_score(y, clusters_adjusted)  \n",
    "    \n",
    "    if(draw_graph and reduction_name != \"None\"):\n",
    "        print(f\"ARI Score ({supervised_name} - {reduction_name}) : %.2f\" % ari_score)  \n",
    "        print(f\"ACCURACY ({supervised_name} - {reduction_name}) : %.2f\" % accuracy)  \n",
    "        \n",
    "        # Plot on the left the datapoints with existing categories  \n",
    "        plt.figure(figsize=(12, 3))  \n",
    "        plt.subplot(1, 2, 1)  \n",
    "        sns.scatterplot(x=X_reduced[:, 0], y=X_reduced[:, 1], hue=original_df['cat'], palette='Set1')  \n",
    "        plt.title(f\"Real Categories {supervised_name} - {reduction_name}\")  \n",
    "        plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)  \n",
    "        \n",
    "        # Plot on the right the datapoints with determined categories\n",
    "        plt.subplot(1, 2, 2)  \n",
    "        sns.scatterplot(x=X_reduced[:, 0], y=X_reduced[:, 1], hue=y_pred_full, palette='Set1')  \n",
    "        plt.title(f\"Predicted Categories {supervised_name} - {reduction_name}\")  \n",
    "        plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)  \n",
    "    \n",
    "        plt.tight_layout()  \n",
    "        plt.show()\n",
    "    \n",
    "    return {\"label\": f\"{reduction_name}\", \"model\": f\"{supervised_name}\", \"ari_score\": ari_score,\"accuracy\": accuracy, \"clusters\": y_pred_full}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maintenant pour ma propre connaissance, je veux faire un test de précision sur plusieurs modèles ainsi que plusieurs hypothèses.\n",
    "Je regroupe le tout dans un tableau qui sera mon benchmark leaderboard.\n",
    "\n",
    "Un peu overkill mais très utile pour ma compréhension et futurs projets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_by_df_supervised = [\n",
    "    {\"name\": \"all_with_lemm\", \"scores\": calculate_accuracy_from_df(df_clean_lemm[\"clean_desc\"], True)},\n",
    "    {\"name\": \"all_with_stemm\", \"scores\": calculate_accuracy_from_df(df_clean_stemm[\"clean_desc\"], True)},\n",
    "    {\"name\": \"raw\", \"scores\": calculate_accuracy_from_df(df[\"description\"], True)},\n",
    "    {\"name\": \"step1\", \"scores\": calculate_accuracy_from_df(df_clean[\"clean_desc_step1\"], True)},\n",
    "    {\"name\": \"step2\", \"scores\": calculate_accuracy_from_df(df_clean[\"clean_desc_step2\"], True)},\n",
    "    {\"name\": \"step3\", \"scores\": calculate_accuracy_from_df(df_clean[\"clean_desc_step3\"], True)},\n",
    "    {\"name\": \"step4\", \"scores\": calculate_accuracy_from_df(df_clean[\"clean_desc_step4\"], True)},\n",
    "    {\"name\": \"step5\", \"scores\": calculate_accuracy_from_df(df_clean[\"clean_desc_step5\"], True)},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_scores_dfs_supervised = pd.DataFrame({\"dataframe\":[], \"feature_extraction\":[], \"reduction_method\": [], \"ari\": [], \"accuracy\":[], \"full_label\":[] })\n",
    "for _, df_item in enumerate(scores_by_df_supervised):\n",
    "    for _, global_score in enumerate(df_item[\"scores\"]):\n",
    "        global_score[\"values\"][\"dataframe\"] = df_item[\"name\"]\n",
    "        global_score[\"values\"][\"feature_extraction\"] = global_score[\"name\"]\n",
    "        global_score[\"values\"] = global_score[\"values\"].rename(columns={'label': 'reduction_method'})\n",
    "        global_score[\"values\"][\"full_label\"] = global_score[\"values\"].apply(lambda row: f'{df_item[\"name\"]}-{global_score[\"name\"]}-{row[\"reduction_method\"]}-{row[\"model\"]}', axis=1)  \n",
    "        full_scores_dfs_supervised = pd.concat([full_scores_dfs_supervised, global_score[\"values\"]], ignore_index=True)\n",
    "        # for _, score in enumerate(global_score[\"values\"]):\n",
    "        #     # print(f'Label = {score[\"label\"]}')\n",
    "        #     # print(f'Label = {score[\"label\"]}, accuracy = {score[\"accuracy\"]}')\n",
    "        #     print(global_score[\"values\"].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "J'affiche le top 20 puis le bottom 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort the dataframe by accuracy in descending order  \n",
    "sorted_df_supervised = full_scores_dfs_supervised.sort_values(by='accuracy', ascending=False)  \n",
    "  \n",
    "# Select the top 20 records  \n",
    "top_20_df_supervised = sorted_df_supervised.head(20).reset_index()\n",
    "  \n",
    "# Create the bar plot  \n",
    "plt.figure(figsize=(10, 6))  \n",
    "ax = sns.barplot(data=top_20_df_supervised, x='accuracy', y='full_label', orient='h')  \n",
    "plt.xlabel('Accuracy')\n",
    "plt.ylabel('Full Label')\n",
    "plt.title('Top 20 by Accuracy')\n",
    "\n",
    "# Add accuracy scores within each bar  \n",
    "for index, row in top_20_df_supervised.iterrows():  \n",
    "    ax.text(0.06, index + 0.2, f\"{row['accuracy']:.3f}\", color='black', ha=\"right\")  \n",
    "  \n",
    "\n",
    "plt.show()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort the dataframe by accuracy in descending order  \n",
    "sorted_df_supervised = full_scores_dfs_supervised.sort_values(by='accuracy', ascending=True)  \n",
    "  \n",
    "# Select the top 20 records  \n",
    "low_20_df_supervised = sorted_df_supervised.head(20).reset_index()\n",
    "  \n",
    "# Create the bar plot  \n",
    "plt.figure(figsize=(10, 6))  \n",
    "ax = sns.barplot(data=low_20_df_supervised, x='accuracy', y='full_label', orient='h')  \n",
    "plt.xlabel('Accuracy')\n",
    "plt.ylabel('Full Label')\n",
    "plt.title('Worst 20 by Accuracy')\n",
    "\n",
    "# Add accuracy scores within each bar  \n",
    "for index, row in low_20_df_supervised.iterrows():  \n",
    "    ax.text(0.06, index + 0.2, f\"{row['accuracy']:.3f}\", color='black', ha=\"right\")  \n",
    "  \n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "J'observe les clusters sur le meilleur modèles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisation des clusters réels & prédits sur le meilleur dataframe\n",
    "tfidf_vectorizer = TfidfVectorizer()  \n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(df_clean_stemm['clean_desc'])  \n",
    "tfidf_df = pd.DataFrame(tfidf_matrix.toarray(), columns=tfidf_vectorizer.get_feature_names_out())\n",
    "\n",
    "tfidf_df_scores = check_one_df_supervised(tfidf_df, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Axes d'améliorations potentiels:\n",
    "- Prédire les lvls 2/3/n\n",
    "- Ajouter Bigrams/Trigrams"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
