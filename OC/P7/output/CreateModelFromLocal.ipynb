{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BO2Hl9ToQcGn",
        "outputId": "6d3d9cbd-67ba-4847-c46d-5393ce66e9d1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 80.9M  100 80.9M    0     0  1680k      0  0:00:49  0:00:49 --:--:-- 2160k:54  0:00:35  0:00:19 2210k     0  0:00:49  0:00:47  0:00:02 2097k\n",
            "Archive:  sentiment140.zip\n",
            "  inflating: training.1600000.processed.noemoticon.csv  \n"
          ]
        }
      ],
      "source": [
        "!curl -O https://s3-eu-west-1.amazonaws.com/static.oc-static.com/prod/courses/files/AI+Engineer/Project+7%C2%A0-+D%C3%A9tectez+les+Bad+Buzz+gr%C3%A2ce+au+Deep+Learning/sentiment140.zip\n",
        "!unzip -o sentiment140.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BwiwQ0OhSaq-",
        "outputId": "b7efa411-4d97-4fc2-82a8-a07ceac6b189"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: demoji in ./venv/lib/python3.10/site-packages (1.1.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "uByU6bfMQyTL"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "import json\n",
        "import re\n",
        "import string\n",
        "import demoji\n",
        "from tqdm import tqdm\n",
        "\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from joblib import Parallel, delayed\n",
        "from gensim.models import Word2Vec\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "import sys\n",
        "import sklearn\n",
        "import gensim\n",
        "import tqdm as tq\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lc1DdSDlnszx",
        "outputId": "f653fc3e-cac1-4409-e4f7-76d35cae0178"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Python Version: 3.10.12 (main, Jul  5 2023, 15:02:25) [Clang 14.0.6 ]\n",
            "TensorFlow Version: 2.15.0\n",
            "Scikit-Learn Versionb: 1.2.2\n",
            "Pandas Version: 1.5.3\n",
            "Demoji Version: 1.1.0\n",
            "tqdm Version: 4.66.1\n",
            "gensim Version: 4.3.2\n"
          ]
        }
      ],
      "source": [
        "print(\"Python Version:\", sys.version)\n",
        "print(\"TensorFlow Version:\", tf.__version__)\n",
        "print(\"Scikit-Learn Versionb:\", sklearn.__version__)\n",
        "print(\"Pandas Version:\", pd.__version__)\n",
        "print(\"Demoji Version:\", demoji.__version__)\n",
        "print(\"tqdm Version:\", tq.__version__)\n",
        "print(\"gensim Version:\", gensim.__version__)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "TPWbPWFH8Ajm"
      },
      "outputs": [],
      "source": [
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "tf.keras.backend.set_floatx('float32')\n",
        "os.environ['TF_DETERMINISTIC_OPS'] = '1'\n",
        "os.environ['PYTHONHASHSEED'] = str(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MqxuS0RjmTTu",
        "outputId": "d1c20fd8-ca76-4843-c6c3-91f186c58cb9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /var/folders/x_/0z24g8110_n09vlvhxmrh0_w0000gp/T/ipykernel_8029/3420453341.py:1: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.config.list_physical_devices('GPU')` instead.\n",
            "GPU is enabled!\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-02-06 18:07:41.433754: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M2\n",
            "2024-02-06 18:07:41.433771: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 24.00 GB\n",
            "2024-02-06 18:07:41.433777: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 8.00 GB\n",
            "2024-02-06 18:07:41.433811: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
            "2024-02-06 18:07:41.433824: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
          ]
        }
      ],
      "source": [
        "if tf.test.is_gpu_available():\n",
        "    print(\"GPU is enabled!\")\n",
        "else:\n",
        "    print(\"GPU is not enabled.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "wWIkoHVdR3iZ"
      },
      "outputs": [],
      "source": [
        "cols = ['sentiment', 'timestamp', 'date', \"query\", \"username\", \"comment\"]\n",
        "df = pd.read_csv(\"./training.1600000.processed.noemoticon.csv\", encoding='ISO-8859-1', header=None, names=cols)\n",
        "# df = df.sample(n=100000, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "id": "qLazq9_2R5N9",
        "outputId": "d17289da-640c-4258-ac36-7f763d601664"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(1600000, 6)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentiment</th>\n",
              "      <th>timestamp</th>\n",
              "      <th>date</th>\n",
              "      <th>query</th>\n",
              "      <th>username</th>\n",
              "      <th>comment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1467810369</td>\n",
              "      <td>Mon Apr 06 22:19:45 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>_TheSpecialOne_</td>\n",
              "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>1467810672</td>\n",
              "      <td>Mon Apr 06 22:19:49 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>scotthamilton</td>\n",
              "      <td>is upset that he can't update his Facebook by ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>1467810917</td>\n",
              "      <td>Mon Apr 06 22:19:53 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>mattycus</td>\n",
              "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>1467811184</td>\n",
              "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>ElleCTF</td>\n",
              "      <td>my whole body feels itchy and like its on fire</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>1467811193</td>\n",
              "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>Karoli</td>\n",
              "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   sentiment   timestamp                          date     query  \\\n",
              "0          0  1467810369  Mon Apr 06 22:19:45 PDT 2009  NO_QUERY   \n",
              "1          0  1467810672  Mon Apr 06 22:19:49 PDT 2009  NO_QUERY   \n",
              "2          0  1467810917  Mon Apr 06 22:19:53 PDT 2009  NO_QUERY   \n",
              "3          0  1467811184  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n",
              "4          0  1467811193  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n",
              "\n",
              "          username                                            comment  \n",
              "0  _TheSpecialOne_  @switchfoot http://twitpic.com/2y1zl - Awww, t...  \n",
              "1    scotthamilton  is upset that he can't update his Facebook by ...  \n",
              "2         mattycus  @Kenichan I dived many times for the ball. Man...  \n",
              "3          ElleCTF    my whole body feels itchy and like its on fire   \n",
              "4           Karoli  @nationwideclass no, it's not behaving at all....  "
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "print(df.shape)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "iGguQs2iSFGd"
      },
      "outputs": [],
      "source": [
        "def clean_tweet(doc):\n",
        "  # Lower the code\n",
        "  doc = doc.lower().strip()\n",
        "  #remove emoji\n",
        "  text = demoji.replace(doc, '')\n",
        "  #remove links\n",
        "  text = re.sub(r'http\\S+|www.\\S+', '', text)\n",
        "  # # Remove mentions\n",
        "  text = re.sub(r'@\\w+', '', text)\n",
        "  # Remove hashtag symbol but keep the text\n",
        "  text = re.sub(r'#(\\w+)', r'\\1', text)\n",
        "  # Keep only alphanumeric characters and spaces\n",
        "  text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
        "  # Remove multiple spaces (replace them with a single space)\n",
        "  text = re.sub(r'\\s+', ' ', text).strip()\n",
        "\n",
        "  return text\n",
        "\n",
        "def clean_df(dataframe):\n",
        "  df = dataframe.copy()\n",
        "  # Keep only comment and sentiment columns\n",
        "  df = df[[\"comment\",\"sentiment\"]]\n",
        "\n",
        "  # negative field 0 = 0\n",
        "  # Map positive field 4 = 1\n",
        "  df.loc[df['sentiment'] == 4, 'sentiment'] = 1\n",
        "\n",
        "  # Clean the comment\n",
        "  df['comment_clean'] = parallelize_on_rows(df['comment'], clean_tweet)\n",
        "\n",
        "  # Count the number of words from comment & comment_cleam\n",
        "  df['words_nb'] = parallelize_on_rows(df['comment'], lambda x: len(x.split()))\n",
        "  df['words_nb_clean'] = parallelize_on_rows(df['comment_clean'], lambda x: len(x.split()))\n",
        "\n",
        "  # Only keep the clean words\n",
        "  df = df[df['words_nb_clean'] > 3]\n",
        "\n",
        "  # Remove duplicate\n",
        "  df.drop_duplicates(subset='comment',inplace=True)\n",
        "\n",
        "  return df\n",
        "\n",
        "\n",
        "def parallelize_on_rows(data, func):\n",
        "    r = Parallel(n_jobs=-1)(delayed(func)(i) for i in tqdm(data, desc=\"Processing\"))\n",
        "    return r"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sYkOsu5kSlka",
        "outputId": "5c9d1d29-769e-4938-b1b5-cb4bedeb3d20"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing: 100%|██████████| 1600000/1600000 [01:25<00:00, 18783.23it/s]\n",
            "Processing: 100%|██████████| 1600000/1600000 [00:02<00:00, 549788.48it/s]\n",
            "Processing: 100%|██████████| 1600000/1600000 [00:02<00:00, 560917.16it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(1469994, 5)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>comment</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>comment_clean</th>\n",
              "      <th>words_nb</th>\n",
              "      <th>words_nb_clean</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
              "      <td>0</td>\n",
              "      <td>awww thats a bummer you shoulda got david carr...</td>\n",
              "      <td>19</td>\n",
              "      <td>16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>is upset that he can't update his Facebook by ...</td>\n",
              "      <td>0</td>\n",
              "      <td>is upset that he cant update his facebook by t...</td>\n",
              "      <td>21</td>\n",
              "      <td>21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
              "      <td>0</td>\n",
              "      <td>i dived many times for the ball managed to sav...</td>\n",
              "      <td>18</td>\n",
              "      <td>16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>my whole body feels itchy and like its on fire</td>\n",
              "      <td>0</td>\n",
              "      <td>my whole body feels itchy and like its on fire</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
              "      <td>0</td>\n",
              "      <td>no its not behaving at all im mad why am i her...</td>\n",
              "      <td>21</td>\n",
              "      <td>20</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                             comment  sentiment  \\\n",
              "0  @switchfoot http://twitpic.com/2y1zl - Awww, t...          0   \n",
              "1  is upset that he can't update his Facebook by ...          0   \n",
              "2  @Kenichan I dived many times for the ball. Man...          0   \n",
              "3    my whole body feels itchy and like its on fire           0   \n",
              "4  @nationwideclass no, it's not behaving at all....          0   \n",
              "\n",
              "                                       comment_clean  words_nb  words_nb_clean  \n",
              "0  awww thats a bummer you shoulda got david carr...        19              16  \n",
              "1  is upset that he cant update his facebook by t...        21              21  \n",
              "2  i dived many times for the ball managed to sav...        18              16  \n",
              "3     my whole body feels itchy and like its on fire        10              10  \n",
              "4  no its not behaving at all im mad why am i her...        21              20  "
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = clean_df(df)\n",
        "print(df.shape)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "HzVE-mfSSnAf"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-02-06 18:10:12.625966: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
            "2024-02-06 18:10:12.625984: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "   1/4135 [..............................] - ETA: 21:30 - loss: 0.7818 - accuracy: 0.5156"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-02-06 18:10:13.227226: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:117] Plugin optimizer for device_type GPU is enabled.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "4135/4135 [==============================] - 24s 6ms/step - loss: 0.5433 - accuracy: 0.7257 - val_loss: 0.5394 - val_accuracy: 0.7277\n",
            "Epoch 2/20\n",
            "4135/4135 [==============================] - 23s 6ms/step - loss: 0.5397 - accuracy: 0.7290 - val_loss: 0.5379 - val_accuracy: 0.7309\n",
            "Epoch 3/20\n",
            "4135/4135 [==============================] - 23s 6ms/step - loss: 0.5404 - accuracy: 0.7287 - val_loss: 0.5384 - val_accuracy: 0.7290\n",
            "Epoch 4/20\n",
            "4135/4135 [==============================] - 23s 6ms/step - loss: 0.5408 - accuracy: 0.7284 - val_loss: 0.5377 - val_accuracy: 0.7300\n",
            "Epoch 5/20\n",
            "4135/4135 [==============================] - 23s 6ms/step - loss: 0.5414 - accuracy: 0.7277 - val_loss: 0.5383 - val_accuracy: 0.7286\n",
            "Epoch 6/20\n",
            "4135/4135 [==============================] - 23s 6ms/step - loss: 0.5417 - accuracy: 0.7277 - val_loss: 0.5407 - val_accuracy: 0.7280\n",
            "Epoch 7/20\n",
            "4135/4135 [==============================] - 23s 6ms/step - loss: 0.5424 - accuracy: 0.7274 - val_loss: 0.5394 - val_accuracy: 0.7286\n",
            "Epoch 8/20\n",
            "4135/4135 [==============================] - 23s 6ms/step - loss: 0.5428 - accuracy: 0.7266 - val_loss: 0.5445 - val_accuracy: 0.7252\n",
            "Epoch 9/20\n",
            "4135/4135 [==============================] - 23s 6ms/step - loss: 0.5434 - accuracy: 0.7269 - val_loss: 0.5422 - val_accuracy: 0.7243\n",
            "Epoch 10/20\n",
            "4135/4135 [==============================] - 23s 6ms/step - loss: 0.5437 - accuracy: 0.7260 - val_loss: 0.5450 - val_accuracy: 0.7278\n",
            "Epoch 11/20\n",
            "4135/4135 [==============================] - 23s 6ms/step - loss: 0.5442 - accuracy: 0.7258 - val_loss: 0.5466 - val_accuracy: 0.7207\n",
            "Epoch 12/20\n",
            "4135/4135 [==============================] - 23s 6ms/step - loss: 0.5447 - accuracy: 0.7258 - val_loss: 0.5380 - val_accuracy: 0.7296\n",
            "Epoch 13/20\n",
            "4135/4135 [==============================] - 23s 6ms/step - loss: 0.5445 - accuracy: 0.7258 - val_loss: 0.5466 - val_accuracy: 0.7221\n",
            "Epoch 14/20\n",
            "4135/4135 [==============================] - 23s 6ms/step - loss: 0.5456 - accuracy: 0.7250 - val_loss: 0.5580 - val_accuracy: 0.7113\n",
            "Epoch 15/20\n",
            "4135/4135 [==============================] - 23s 6ms/step - loss: 0.5457 - accuracy: 0.7253 - val_loss: 0.5395 - val_accuracy: 0.7287\n",
            "Epoch 16/20\n",
            "4135/4135 [==============================] - 23s 6ms/step - loss: 0.5459 - accuracy: 0.7249 - val_loss: 0.5587 - val_accuracy: 0.7150\n",
            "Epoch 17/20\n",
            "4135/4135 [==============================] - 24s 6ms/step - loss: 0.5461 - accuracy: 0.7249 - val_loss: 0.5407 - val_accuracy: 0.7266\n",
            "Epoch 18/20\n",
            "4135/4135 [==============================] - 24s 6ms/step - loss: 0.5466 - accuracy: 0.7246 - val_loss: 0.5578 - val_accuracy: 0.7186\n",
            "Epoch 19/20\n",
            "4135/4135 [==============================] - 24s 6ms/step - loss: 0.5471 - accuracy: 0.7243 - val_loss: 0.5399 - val_accuracy: 0.7269\n",
            "Epoch 20/20\n",
            "4135/4135 [==============================] - 24s 6ms/step - loss: 0.5481 - accuracy: 0.7238 - val_loss: 0.5428 - val_accuracy: 0.7298\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x1720ee890>"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Function to vectorize a comment based on mean of all word vectors in the comment\n",
        "def comment_to_vec(comment, model):\n",
        "    vec = np.zeros(model.vector_size)\n",
        "    num_words = 0\n",
        "    for word in comment:\n",
        "        if word in model.wv:\n",
        "            vec += model.wv[word]\n",
        "            num_words += 1\n",
        "    if num_words > 0:\n",
        "        vec /= num_words\n",
        "    return vec\n",
        "\n",
        "comments = [row.split() for row in df['comment_clean']]\n",
        "word2vec_model = Word2Vec(comments, vector_size=100, window=5, min_count=1, workers=4)\n",
        "\n",
        "# Vectorize all comments\n",
        "vectorized_comments = np.array([comment_to_vec(comment, word2vec_model) for comment in comments])\n",
        "# Preparing the labels\n",
        "labels = df['sentiment'].values\n",
        "\n",
        "# Split the dataset into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(vectorized_comments, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "model = Sequential([\n",
        "    Dense(32, activation='relu', input_dim=100),  # Reduced the layer sizes for simplicity\n",
        "    Dense(1, activation='sigmoid')  # Keeping the output layer same for binary classification\n",
        "])\n",
        "\n",
        "model.compile(optimizer=\"adam\", loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train, epochs=20, batch_size=256, validation_split=0.1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "9188/9188 [==============================] - 10s 1ms/step\n",
            "0.7298528226286484\n"
          ]
        }
      ],
      "source": [
        "with tf.device('/GPU:0'):\n",
        "    y_pred = model.predict(X_test)  \n",
        "    y_pred_rounded = (y_pred > 0.5).astype(int)  # Convert probabilities to binary predictions (0 or 1)\n",
        "    accuracy = accuracy_score(y_test, y_pred_rounded)\n",
        "    print(accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "9188/9188 [==============================] - 10s 1ms/step\n",
            "0.5485528862343069\n"
          ]
        }
      ],
      "source": [
        "with tf.device('/CPU:0'):\n",
        "    y_pred = model.predict(X_test)  \n",
        "    y_pred_rounded = (y_pred > 0.5).astype(int)  # Convert probabilities to binary predictions (0 or 1)\n",
        "    accuracy = accuracy_score(y_test, y_pred_rounded)\n",
        "    print(accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "7PTyykJJTrPm"
      },
      "outputs": [],
      "source": [
        "def predict_sentiment(comment, model, vector_model):\n",
        "  cleaned_comment = comment.split() # placeholder for actual preprocessing\n",
        "  vec = comment_to_vec(cleaned_comment, vector_model).reshape(1, -1)\n",
        "  prediction = model.predict(vec)\n",
        "\n",
        "  return prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "84C1IymfT5T-"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GPU\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "[[0.09909298]]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "[[0.659521]]\n",
            "\n",
            "CPU\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "[[7.2889725e-06]]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "[[1.1337466e-35]]\n"
          ]
        }
      ],
      "source": [
        "print(\"GPU\")\n",
        "with tf.device('/GPU:0'):\n",
        "    print(predict_sentiment(\"I am so sad, this is very bad news, terrible!\", model, word2vec_model))\n",
        "    print(predict_sentiment(\"I am so happy, this is very good news, congrats!\", model, word2vec_model))\n",
        "\n",
        "print(\"\\nCPU\")\n",
        "with tf.device('/CPU:0'):\n",
        "  print(predict_sentiment(\"I am so sad, this is very bad news, terrible!\", model, word2vec_model))\n",
        "  print(predict_sentiment(\"I am so happy, this is very good news, congrats!\", model, word2vec_model))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
