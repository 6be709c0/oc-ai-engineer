{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modèle avancé"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os  \n",
    "import json  \n",
    "import re  \n",
    "import string\n",
    "import demoji\n",
    "from tqdm import tqdm\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from joblib import Parallel, delayed\n",
    "from gensim.models import Word2Vec  \n",
    "\n",
    "from sklearn.model_selection import train_test_split  \n",
    "from sklearn.metrics import accuracy_score\n",
    "import sklearn\n",
    "from tensorflow.keras import Sequential  \n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "import sys\n",
    "import sklearn\n",
    "import gensim\n",
    "import tqdm as tq\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python Version: 3.10.12 (main, Jul  5 2023, 15:02:25) [Clang 14.0.6 ]\n",
      "TensorFlow Version: 2.15.0\n",
      "Scikit-Learn Version: 1.2.2\n",
      "Pandas Version: 1.5.3\n",
      "Demoji Version: 1.1.0\n",
      "tqdm Version: 4.66.1\n",
      "gensim Version: 4.3.2\n"
     ]
    }
   ],
   "source": [
    "print(\"Python Version:\", sys.version)  \n",
    "print(\"TensorFlow Version:\", tf.__version__)  \n",
    "print(\"Scikit-Learn Version:\", sklearn.__version__)  \n",
    "print(\"Pandas Version:\", pd.__version__)  \n",
    "print(\"Demoji Version:\", demoji.__version__) \n",
    "print(\"tqdm Version:\", tq.__version__) \n",
    "print(\"gensim Version:\", gensim.__version__) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU is enabled!\n"
     ]
    }
   ],
   "source": [
    "if tf.config.list_physical_devices('GPU'):  \n",
    "    print(\"GPU is enabled!\")  \n",
    "else:  \n",
    "    print(\"GPU is not enabled.\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-06 15:57:06.482441: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2024-02-06 15:57:06.482459: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "with open(\"./google/model.pkl\", \"rb\") as file:  \n",
    "    model = pickle.load(file)  \n",
    "  \n",
    "with open(\"./google/vector_model.pkl\", \"rb\") as file:  \n",
    "    vector_model = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def comment_to_vec(comment, model):\n",
    "    vec = np.zeros(model.vector_size)\n",
    "    num_words = 0\n",
    "    for word in comment:\n",
    "        if word in model.wv:\n",
    "            vec += model.wv[word]\n",
    "            num_words += 1\n",
    "    if num_words > 0:\n",
    "        vec /= num_words\n",
    "    return vec\n",
    "  \n",
    "def clean_tweet(doc):  \n",
    "  # Lower the code\n",
    "  doc = doc.lower().strip()\n",
    "  #remove emoji\n",
    "  text = demoji.replace(doc, '')\n",
    "  #remove links\n",
    "  text = re.sub(r'http\\S+|www.\\S+', '', text)  \n",
    "  # # Remove mentions\n",
    "  text = re.sub(r'@\\w+', '', text) \n",
    "  # Remove hashtag symbol but keep the text  \n",
    "  text = re.sub(r'#(\\w+)', r'\\1', text)\n",
    "  # Keep only alphanumeric characters and spaces  \n",
    "  text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "  # Remove multiple spaces (replace them with a single space)  \n",
    "  text = re.sub(r'\\s+', ' ', text).strip()\n",
    "  \n",
    "  return text\n",
    "    \n",
    "def clean_df(dataframe):\n",
    "  df = dataframe.copy()\n",
    "  # Keep only comment and sentiment columns\n",
    "  df = df[[\"comment\",\"sentiment\"]]\n",
    "  \n",
    "  # negative field 0 = 0\n",
    "  # Map positive field 4 = 1\n",
    "  df.loc[df['sentiment'] == 4, 'sentiment'] = 1  \n",
    "  \n",
    "  # Clean the comment\n",
    "  df['comment_clean'] = parallelize_on_rows(df['comment'], clean_tweet)  \n",
    "  \n",
    "  # Count the number of words from comment & comment_cleam\n",
    "  df['words_nb'] = parallelize_on_rows(df['comment'], lambda x: len(x.split()))  \n",
    "  df['words_nb_clean'] = parallelize_on_rows(df['comment_clean'], lambda x: len(x.split()))  \n",
    "  \n",
    "  # Only keep the clean words\n",
    "  df = df[df['words_nb_clean'] > 3]\n",
    "  \n",
    "  # Remove duplicate\n",
    "  df.drop_duplicates(subset='comment',inplace=True)\n",
    "  \n",
    "  return df\n",
    "\n",
    "\n",
    "def parallelize_on_rows(data, func):  \n",
    "    r = Parallel(n_jobs=-1)(delayed(func)(i) for i in tqdm(data, desc=\"Processing\"))  \n",
    "    return r  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_sentiment(comment, model, vector_model):\n",
    "  cleaned_comment = comment.split() # placeholder for actual preprocessing\n",
    "  vec = comment_to_vec(cleaned_comment, vector_model).reshape(1, -1)\n",
    "  prediction = model.predict(vec)\n",
    "\n",
    "  return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU\n",
      "1/1 [==============================] - 0s 69ms/step\n",
      "[[0.9649106]]\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "[[0.99831223]]\n",
      "\n",
      "CPU\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "[[0.08758987]]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "[[0.85165584]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-06 15:57:06.867469: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:117] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    }
   ],
   "source": [
    "print(\"GPU\")\n",
    "with tf.device('/GPU:0'):\n",
    "    print(predict_sentiment(\"I am so sad, this is very bad news, terrible!\", model, vector_model))\n",
    "    print(predict_sentiment(\"I am so happy, this is very good news, congrats!\", model, vector_model))\n",
    "\n",
    "print(\"\\nCPU\")\n",
    "with tf.device('/CPU:0'):\n",
    "  print(predict_sentiment(\"I am so sad, this is very bad news, terrible!\", model, vector_model))\n",
    "  print(predict_sentiment(\"I am so happy, this is very good news, congrats!\", model, vector_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
