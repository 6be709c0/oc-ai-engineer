{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import mlflow.keras\n",
    "from keras.preprocessing.text import tokenizer_from_json  \n",
    "from keras.preprocessing.sequence import pad_sequences  \n",
    "import json\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/m/miniconda3/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Downloading artifacts:   0%|          | 0/12 [00:00<?, ?it/s]2024/02/05 16:10:23 INFO mlflow.store.artifact.artifact_repo: The progress bar can be disabled by setting the environment variable MLFLOW_ENABLE_ARTIFACTS_PROGRESS_BAR to false\n",
      "Downloading artifacts: 100%|██████████| 12/12 [00:02<00:00,  4.64it/s] \n",
      "2024-02-05 16:10:25.763760: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M2\n",
      "2024-02-05 16:10:25.763784: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 24.00 GB\n",
      "2024-02-05 16:10:25.763795: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 8.00 GB\n",
      "2024-02-05 16:10:25.763832: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2024-02-05 16:10:25.763848: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n",
      "Downloading artifacts: 100%|██████████| 1/1 [00:00<00:00,  1.21it/s]\n"
     ]
    }
   ],
   "source": [
    "mlflow.set_tracking_uri(uri=\"http://127.0.0.1:5000\")\n",
    "\n",
    "run_id=\"18adea9281a64c5b9867b96d120f0f42\"\n",
    "\n",
    "loaded_model = mlflow.keras.load_model(f\"runs:/{run_id}/model\")  \n",
    "client = mlflow.tracking.MlflowClient()\n",
    "tokenizer_artifact_path = client.download_artifacts(run_id=run_id, path=\"tokenizer.json\")  \n",
    "tokenizer = tokenizer_from_json(json.load(open(tokenizer_artifact_path, 'r', encoding='utf-8')))\n",
    "run_params = mlflow.get_run(run_id).data.params "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': '0.0008925492035064445',\n",
       " 'input_length': '33',\n",
       " 'experiment_name': 'Tweet Sentiment - 1000 - glove',\n",
       " 'epochs': '8',\n",
       " 'batch_size': '128'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2, 44, 143, 96, 3, 25, 89]]\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "[[0.3306366]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_to_predict = [\"i am very sad to be here\"]  \n",
    "# Tokenizing and padding  \n",
    "sequence = tokenizer.texts_to_sequences(text_to_predict)\n",
    "print(sequence)\n",
    "# We need to pad sequences to ensure uniform input size  \n",
    "padded_sequence = pad_sequences(sequence, maxlen=int(run_params[\"input_length\"]))\n",
    "\n",
    "prediction = loaded_model.predict(padded_sequence)\n",
    "print(prediction)\n",
    "sentiment = np.round(prediction).astype(int)[0][0]\n",
    "sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[28, 11, 22, 96]]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0, 28, 11, 22,\n",
       "        96]], dtype=int32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_sequence"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
