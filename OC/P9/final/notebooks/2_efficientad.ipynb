{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Efficient AD Model For Anomaly Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Before running the notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's prepare the environement before running the notebook.  \n",
    "Run the following command in the terminal from the **`final`** folder.\n",
    "\n",
    "```sh\n",
    "conda create -p envs/2_efficientad python=3.9.7 -y\n",
    "conda activate envs/2_efficientad\n",
    "\n",
    "pip install -r requirements/2_efficientad.txt\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Saving channel_mean and channel_std as a .pth file  \n",
    "# torch.save({'mean': channel_mean, 'std': channel_std}, 'normalization_params.pth')\n",
    "# # Loading the parameters back  \n",
    "# params = torch.load('normalization_params.pth')  \n",
    "# channel_mean = params['mean']  \n",
    "# channel_std = params['std']  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../code/')\n",
    "\n",
    "from efficientad import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"seed\": 42,\n",
    "    \"on_gpu\": torch.cuda.is_available(),\n",
    "    \"out_channels\": 384,\n",
    "    \"image_size\": 256,\n",
    "    \"dataset_path\": \"./my_dataset\",\n",
    "    \"subdataset\": \"cookies\",\n",
    "    \"output_dir\": \"../output/1\",\n",
    "    \"train_steps\": 20,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EfficientAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed set (42)\n"
     ]
    }
   ],
   "source": [
    "set_seed(config[\"seed\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_output_dir = os.path.join(config[\"output_dir\"], 'trainings', config[\"subdataset\"])\n",
    "test_output_dir = os.path.join(config[\"output_dir\"], 'anomaly_maps', config[\"subdataset\"], 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms_class = ImageTransforms(config[\"image_size\"])  \n",
    "\n",
    "full_train_set = ImageFolderWithoutTarget(\n",
    "    os.path.join(config[\"dataset_path\"], config[\"subdataset\"], 'train'),\n",
    "    transform=transforms.Lambda(transforms_class.train_transform))\n",
    "\n",
    "test_set = ImageFolderWithPath(\n",
    "    os.path.join(config[\"dataset_path\"], config[\"subdataset\"], 'test'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mvtec dataset paper recommend 10% validation set\n",
    "train_size = int(0.9 * len(full_train_set))\n",
    "validation_size = len(full_train_set) - train_size\n",
    "rng = torch.Generator().manual_seed(config[\"seed\"])\n",
    "train_set, validation_set = torch.utils.data.random_split(full_train_set,\n",
    "                                                    [train_size,\n",
    "                                                    validation_size],\n",
    "                                                    rng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_set, batch_size=1, shuffle=True,\n",
    "                            num_workers=4, pin_memory=True)\n",
    "train_loader_infinite = InfiniteDataloader(train_loader)\n",
    "validation_loader = DataLoader(validation_set, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "penalty_loader_infinite = itertools.repeat(None)\n",
    "teacher = get_pdn_small(config[\"out_channels\"])\n",
    "student = get_pdn_small(2 * config[\"out_channels\"])\n",
    "autoencoder = get_autoencoder(config[\"out_channels\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training\n"
     ]
    }
   ],
   "source": [
    " # teacher frozen\n",
    "teacher.eval()\n",
    "student.train()\n",
    "autoencoder.train()\n",
    "print(\"Training\")\n",
    "\n",
    "if config[\"on_gpu\"]:\n",
    "    teacher.cuda()\n",
    "    student.cuda()\n",
    "    autoencoder.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = torch.load('../output/normalization_params.pth')  \n",
    "teacher_mean = params['mean']  \n",
    "teacher_std = params['std']  \n",
    "\n",
    "# teacher_mean, teacher_std = teacher_normalization(teacher, train_loader, config)\n",
    "# torch.save({'mean': teacher_mean, 'std': teacher_std}, f'../output/normalization_params.pth')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam(\n",
    "    itertools.chain(student.parameters(),\n",
    "    autoencoder.parameters()),\n",
    "    lr=1e-4, weight_decay=1e-5\n",
    ")\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=int(0.95 * config[\"train_steps\"]), gamma=0.1)\n",
    "tqdm_obj = tqdm(range(config[\"train_steps\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Current loss: 29.3504  : 100%|██████████| 20/20 [00:15<00:00,  1.28it/s]\n"
     ]
    }
   ],
   "source": [
    "for iteration, (image_st, image_ae), image_penalty in zip(\n",
    "        tqdm_obj, train_loader_infinite, penalty_loader_infinite):\n",
    "    if config[\"on_gpu\"]:\n",
    "        image_st = image_st.cuda()\n",
    "        image_ae = image_ae.cuda()\n",
    "    with torch.no_grad():\n",
    "        teacher_output_st = teacher(image_st)\n",
    "        teacher_output_st = (teacher_output_st - teacher_mean) / teacher_std\n",
    "    student_output_st = student(image_st)[:, :config[\"out_channels\"]]\n",
    "    distance_st = (teacher_output_st - student_output_st) ** 2\n",
    "    d_hard = torch.quantile(distance_st, q=0.999)\n",
    "    loss_hard = torch.mean(distance_st[distance_st >= d_hard])\n",
    "    loss_st = loss_hard\n",
    "    \n",
    "    ae_output = autoencoder(image_ae)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        teacher_output_ae = teacher(image_ae)\n",
    "        teacher_output_ae = (teacher_output_ae - teacher_mean) / teacher_std\n",
    "    student_output_ae = student(image_ae)[:, config[\"out_channels\"]:]\n",
    "    distance_ae = (teacher_output_ae - ae_output)**2\n",
    "    distance_stae = (ae_output - student_output_ae)**2\n",
    "    loss_ae = torch.mean(distance_ae)\n",
    "    loss_stae = torch.mean(distance_stae)\n",
    "    loss_total = loss_st + loss_ae + loss_stae\n",
    "    optimizer.zero_grad()\n",
    "    loss_total.backward()\n",
    "    optimizer.step()\n",
    "    scheduler.step()\n",
    "    \n",
    "    if iteration % 10 == 0:\n",
    "        tqdm_obj.set_description(\n",
    "            \"Current loss: {:.4f}  \".format(loss_total.item()))\n",
    "\n",
    "    if iteration % 1000 == 0:\n",
    "        torch.save(teacher, os.path.join(train_output_dir,\n",
    "                                            'teacher_tmp.pth'))\n",
    "        torch.save(student, os.path.join(train_output_dir,\n",
    "                                            'student_tmp.pth'))\n",
    "        torch.save(autoencoder, os.path.join(train_output_dir,\n",
    "                                                'autoencoder_tmp.pth'))\n",
    "\n",
    "    if iteration % 10000 == 0 and iteration > 0:\n",
    "        # run intermediate evaluation\n",
    "        teacher.eval()\n",
    "        student.eval()\n",
    "        autoencoder.eval()\n",
    "\n",
    "        q_st_start, q_st_end, q_ae_start, q_ae_end = map_normalization(\n",
    "            validation_loader=validation_loader, teacher=teacher,\n",
    "            student=student, autoencoder=autoencoder,\n",
    "            teacher_mean=teacher_mean, teacher_std=teacher_std,\n",
    "            desc='Intermediate map normalization')\n",
    "        auc = test(\n",
    "            test_set=test_set, teacher=teacher, student=student,\n",
    "            autoencoder=autoencoder, teacher_mean=teacher_mean,\n",
    "            teacher_std=teacher_std, q_st_start=q_st_start,\n",
    "            q_st_end=q_st_end, q_ae_start=q_ae_start, q_ae_end=q_ae_end,\n",
    "            test_output_dir=None, desc='Intermediate inference')\n",
    "        print('Intermediate image auc: {:.4f}'.format(auc))\n",
    "\n",
    "        # teacher frozen\n",
    "        teacher.eval()\n",
    "        student.train()\n",
    "        autoencoder.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval done\n"
     ]
    }
   ],
   "source": [
    "teacher.eval()\n",
    "student.eval()\n",
    "autoencoder.eval()\n",
    "print(\"Eval done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(teacher_mean, os.path.join(train_output_dir, 'teacher_mean.pth'))\n",
    "torch.save(teacher_std, os.path.join(train_output_dir, 'teacher_std.pth'))\n",
    "torch.save(teacher, os.path.join(train_output_dir, 'teacher_final.pth'))\n",
    "torch.save(student, os.path.join(train_output_dir, 'student_final.pth'))\n",
    "torch.save(autoencoder, os.path.join(train_output_dir,'autoencoder_final.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Final map normalization: 100%|██████████| 8/8 [00:01<00:00,  5.59it/s]\n",
      "Final inference: 100%|██████████| 120/120 [00:20<00:00,  5.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final image auc: 73.9000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    " q_st_start, q_st_end, q_ae_start, q_ae_end = map_normalization(config=config,\n",
    "    validation_loader=validation_loader, teacher=teacher, student=student,\n",
    "    autoencoder=autoencoder, teacher_mean=teacher_mean,\n",
    "    teacher_std=teacher_std, desc='Final map normalization')\n",
    "auc = test(config=config,default_transform=transforms_class.default_transform,\n",
    "    test_set=test_set, teacher=teacher, student=student,\n",
    "    autoencoder=autoencoder, teacher_mean=teacher_mean,\n",
    "    teacher_std=teacher_std, q_st_start=q_st_start, q_st_end=q_st_end,\n",
    "    q_ae_start=q_ae_start, q_ae_end=q_ae_end,\n",
    "    test_output_dir=test_output_dir, desc='Final inference')\n",
    "print('Final image auc: {:.4f}'.format(auc))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
