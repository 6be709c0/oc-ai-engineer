{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load datasets\n",
    "df_articles, df_clicks, article_embeddings = load_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_articles shape (364047, 5)\n",
      "article_embeddings shape (364047, 250)\n"
     ]
    }
   ],
   "source": [
    "# preprocess data\n",
    "df_articles = preprocessing_articles(df_articles)\n",
    "df_clicks = preprocessing_clicks(df_clicks)\n",
    "article_embeddings_df = pd.DataFrame(article_embeddings)\n",
    "\n",
    "print(\"df_articles shape\", df_articles.shape)\n",
    "print(\"article_embeddings shape\", article_embeddings_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles_clicked = df_clicks.click_article_id.value_counts().index\n",
    "df_articles = df_articles.loc[articles_clicked]\n",
    "article_embeddings_df = article_embeddings_df.loc[articles_clicked]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_articles shape (46033, 5)\n",
      "article_embeddings shape (46033, 250)\n"
     ]
    }
   ],
   "source": [
    "print(\"df_articles shape\", df_articles.shape)\n",
    "print(\"article_embeddings shape\", article_embeddings_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training clicks shape: (2419742, 14)\n",
      "Validation clicks shape: (269559, 14)\n",
      "Testing clicks shape: (298880, 14)\n",
      "All clicks shape: (2988181, 14)\n"
     ]
    }
   ],
   "source": [
    "def train_test_split_sessions(clicks_df, test_size=0.1, val_size=0.1, random_state=42):\n",
    "    session_ids = clicks_df['session_id'].unique()\n",
    "    train_sessions, test_sessions = train_test_split(session_ids, test_size=test_size, random_state=random_state)\n",
    "    train_sessions, val_sessions = train_test_split(train_sessions, test_size=val_size, random_state=random_state)\n",
    "    \n",
    "    train_df = clicks_df[clicks_df['session_id'].isin(train_sessions)]\n",
    "    val_df = clicks_df[clicks_df['session_id'].isin(val_sessions)]\n",
    "    test_df = clicks_df[clicks_df['session_id'].isin(test_sessions)]\n",
    "    all_df = clicks_df[clicks_df['session_id'].isin(session_ids)]\n",
    "    \n",
    "    return train_df, val_df, test_df, all_df\n",
    " \n",
    "\n",
    "# Split the clicks dataframe\n",
    "train_clicks_df, val_clicks_df, test_clicks_df, all_clicks_df = train_test_split_sessions(df_clicks)\n",
    "\n",
    "print(f\"Training clicks shape: {train_clicks_df.shape}\")\n",
    "print(f\"Validation clicks shape: {val_clicks_df.shape}\")\n",
    "print(f\"Testing clicks shape: {test_clicks_df.shape}\")\n",
    "print(f\"All clicks shape: {all_clicks_df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Merging Articles Embeddings with Articles Metadata\n",
    "\n",
    "# Merging with articles_metadata\n",
    "# articles_merged_df = pd.merge(df_articles, article_embeddings_df, on='article_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 294662/294662 [00:16<00:00, 18079.43it/s]\n",
      "100%|██████████| 80449/80449 [00:02<00:00, 32987.88it/s]\n",
      "100%|██████████| 74242/74242 [00:02<00:00, 34546.04it/s]\n",
      "100%|██████████| 322897/322897 [00:19<00:00, 16409.14it/s]\n"
     ]
    }
   ],
   "source": [
    "tqdm.pandas()\n",
    "\n",
    "def create_user_profiles(clicks_df, article_embeddings_df):\n",
    "    user_profiles = clicks_df.groupby('user_id')['click_article_id'].apply(list).reset_index()\n",
    "    embeddings_dict = article_embeddings_df.T.to_dict('list')\n",
    "    \n",
    "    user_profiles['user_embedding'] = user_profiles['click_article_id'].progress_apply(\n",
    "        lambda x: np.mean([embeddings_dict[article] for article in x if article in embeddings_dict], axis=0)\n",
    "    )\n",
    "    \n",
    "    return user_profiles\n",
    "\n",
    "user_profiles_df_train = create_user_profiles(train_clicks_df, article_embeddings_df)\n",
    "user_profiles_df_test = create_user_profiles(test_clicks_df, article_embeddings_df)\n",
    "user_profiles_df_val = create_user_profiles(val_clicks_df, article_embeddings_df)\n",
    "user_profiles_df_all = create_user_profiles(all_clicks_df, article_embeddings_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "def create_content_based_model(input_dim):\n",
    "    model = models.Sequential()\n",
    "    # Input Layer\n",
    "    model.add(layers.Input(shape=(input_dim,)))\n",
    "    \n",
    "    # Hidden Layers\n",
    "    model.add(layers.Dense(128, activation='relu'))\n",
    "    model.add(layers.Dropout(0.2))\n",
    "    model.add(layers.Dense(64, activation='relu'))\n",
    "    model.add(layers.Dropout(0.2))\n",
    "    \n",
    "    # Output Layer - Predicting the relevance score\n",
    "    model.add(layers.Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    # model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    model.compile(optimizer=Adam(), loss='binary_crossentropy', metrics=[ndcg_5, ndcg_10, mean_mrr, g_auc])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data\n",
    "def prepare_data(user_profiles_df_train, articles_df, articles_embeddings_df):\n",
    "    X = []\n",
    "    y = []\n",
    "    \n",
    "    embeddings_dict = articles_embeddings_df.T.to_dict('list')\n",
    "    \n",
    "    for i, user in tqdm(user_profiles_df_train.iterrows(), total=len(user_profiles_df_train)):\n",
    "        if i >= 500:\n",
    "            break\n",
    "        \n",
    "        user_embedding = user['user_embedding']\n",
    "        clicked_articles = user['click_article_id']\n",
    "        \n",
    "        for article_id in clicked_articles:\n",
    "            if article_id in embeddings_dict:\n",
    "                article_embedding = embeddings_dict[article_id]\n",
    "                combined_features = np.concatenate((user_embedding, article_embedding))\n",
    "                X.append(combined_features)\n",
    "                y.append(1) # Positive sample\n",
    "        \n",
    "        # Add some negative samples for training\n",
    "        negative_samples = articles_df[~articles_df['article_id'].isin(clicked_articles)]['article_id'].sample(n=len(clicked_articles))\n",
    "        \n",
    "        for article_id in negative_samples:\n",
    "            if article_id in embeddings_dict:\n",
    "                article_embedding = embeddings_dict[article_id]\n",
    "                combined_features = np.concatenate((user_embedding, article_embedding))\n",
    "                X.append(combined_features)\n",
    "                y.append(0) # Negative sample\n",
    "                \n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 500/294662 [00:00<09:38, 508.84it/s]\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train = prepare_data(user_profiles_df_train, df_articles, article_embeddings_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 500/74242 [00:00<01:58, 622.96it/s]\n"
     ]
    }
   ],
   "source": [
    "X_val, y_val = prepare_data(user_profiles_df_val, df_articles, article_embeddings_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow.keras.backend as K\n",
    "# import numpy as np\n",
    "# from sklearn.metrics import roc_auc_score\n",
    "# from tqdm import tqdm\n",
    "# import numpy as np\n",
    "\n",
    "# def precision_at_k(true_labels, pred_scores, k=5):\n",
    "#     top_k_indices = np.argsort(pred_scores)[-k:]\n",
    "#     top_k_true_labels = true_labels[top_k_indices]\n",
    "#     return np.sum(top_k_true_labels) / k\n",
    "\n",
    "# def recall_at_k(true_labels, pred_scores, k=5):\n",
    "#     top_k_indices = np.argsort(pred_scores)[-k:]\n",
    "#     top_k_true_labels = true_labels[top_k_indices]\n",
    "#     return np.sum(top_k_true_labels) / np.sum(true_labels)\n",
    "\n",
    "def mrr(labels, predictions):\n",
    "    if len(labels) != len(predictions):\n",
    "        raise ValueError(\"Length of labels and predictions must be equal\")\n",
    "\n",
    "    # Combine labels and predictions, then sort by prediction score in descending order\n",
    "    combined = list(zip(labels, predictions))\n",
    "    combined_sorted = sorted(combined, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    # Identify the rank position of the first relevant item (label == 1)\n",
    "    for idx, (label, _) in enumerate(combined_sorted):\n",
    "        if label == 1:\n",
    "            return 1.0 / (idx + 1)\n",
    "\n",
    "    # If no relevant item is found, return 0\n",
    "    return 0.0\n",
    "\n",
    "\n",
    "# def ndcg_at_k(y_true, y_pred, k=5):\n",
    "#     def compute_dcg(y_true, y_pred, k):\n",
    "#         order = np.argsort(y_pred)[::-1]\n",
    "#         y_true = np.take(y_true, order[:k])\n",
    "#         gains = 2 ** y_true - 1\n",
    "#         discounts = np.log2(np.arange(len(y_true)) + 2)\n",
    "#         return np.sum(gains / discounts)\n",
    "\n",
    "#     def compute_ndcg(y_true, y_pred, k):\n",
    "#         dcg = compute_dcg(y_true, y_pred, k)\n",
    "#         ideal_dcg = compute_dcg(y_true, y_true, k)  # Ideal sorted DCG\n",
    "#         return dcg / ideal_dcg if ideal_dcg > 0 else 0\n",
    "\n",
    "#     return tf.py_function(compute_ndcg, (y_true, y_pred, k), tf.double)\n",
    "\n",
    "# def g_auc(y_true, y_pred, user_ids):\n",
    "#     def compute_auc(y_true, y_pred, user_ids):\n",
    "#         users = np.unique(user_ids)\n",
    "#         aucs = []\n",
    "#         for user in users:\n",
    "#             user_indices = np.where(user_ids == user)[0]\n",
    "#             user_indices = tf.constant(user_indices, dtype=tf.int32)\n",
    "            \n",
    "#             user_true = tf.gather(y_true, user_indices)\n",
    "#             user_pred = tf.gather(y_pred, user_indices)\n",
    "            \n",
    "#             user_true_np = user_true.numpy()\n",
    "#             user_pred_np = user_pred.numpy()\n",
    "\n",
    "#             if len(np.unique(user_true_np)) > 1:  # Avoid cases where true labels are all the same\n",
    "#                 auc = roc_auc_score(user_true_np, user_pred_np)\n",
    "#                 aucs.append(auc)\n",
    "#         return np.mean(aucs) if aucs else 0.\n",
    "\n",
    "#     return tf.py_function(compute_auc, (y_true, y_pred, user_ids), tf.double)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 128)               64128     \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 128)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 72449 (283.00 KB)\n",
      "Trainable params: 72449 (283.00 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Assuming article_embeddings's second dimension size is 250\n",
    "input_dim = X_train.shape[1]\n",
    "content_based_model = create_content_based_model(input_dim)\n",
    "\n",
    "content_based_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.21033628, -0.96357318, -0.19693483, ..., -0.4184863 ,\n",
       "         0.1679776 ,  0.27869353],\n",
       "       [-0.21033628, -0.96357318, -0.19693483, ..., -0.39606935,\n",
       "         0.30193529,  0.48606798],\n",
       "       [-0.21033628, -0.96357318, -0.19693483, ..., -0.0688789 ,\n",
       "         0.24662791, -0.00772025],\n",
       "       ...,\n",
       "       [-0.46035395, -0.97221979,  0.08281855, ...,  0.27636528,\n",
       "         0.85097331,  0.57291663],\n",
       "       [-0.46035395, -0.97221979,  0.08281855, ..., -0.60704958,\n",
       "        -0.03966475, -0.49296063],\n",
       "       [-0.46035395, -0.97221979,  0.08281855, ...,  0.70272529,\n",
       "        -0.16361353,  0.03004179]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "696/709 [============================>.] - ETA: 0s - loss: 0.5090 - ndcg_5: 0.4741 - ndcg_10: 0.4741 - mean_mrr: 0.0601 - g_auc: 0.8260\n",
      "\n",
      "Epoch 1: \n",
      "- loss: 0.5084, \n",
      "- ndcg_5: 0.4753, \n",
      "- ndcg_10: 0.4753, \n",
      "- mean_mrr: 0.0604, \n",
      "- g_auc: 0.8267, \n",
      "- val_loss: 0.4117, \n",
      "- val_ndcg_5: 0.5318, \n",
      "- val_ndcg_10: 0.5318, \n",
      "- val_mean_mrr: 0.0674, \n",
      "- val_g_auc: 0.8877, \n",
      "\n",
      "709/709 [==============================] - 2s 2ms/step - loss: 0.5084 - ndcg_5: 0.4753 - ndcg_10: 0.4753 - mean_mrr: 0.0604 - g_auc: 0.8267 - val_loss: 0.4117 - val_ndcg_5: 0.5318 - val_ndcg_10: 0.5318 - val_mean_mrr: 0.0674 - val_g_auc: 0.8877\n",
      "Epoch 2/10\n",
      "707/709 [============================>.] - ETA: 0s - loss: 0.4405 - ndcg_5: 0.5149 - ndcg_10: 0.5149 - mean_mrr: 0.0653 - g_auc: 0.8781\n",
      "\n",
      "Epoch 2: \n",
      "- loss: 0.4403, \n",
      "- ndcg_5: 0.5134, \n",
      "- ndcg_10: 0.5134, \n",
      "- mean_mrr: 0.0651, \n",
      "- g_auc: 0.8782, \n",
      "- val_loss: 0.3798, \n",
      "- val_ndcg_5: 0.5318, \n",
      "- val_ndcg_10: 0.5318, \n",
      "- val_mean_mrr: 0.0674, \n",
      "- val_g_auc: 0.9018, \n",
      "\n",
      "709/709 [==============================] - 1s 2ms/step - loss: 0.4403 - ndcg_5: 0.5134 - ndcg_10: 0.5134 - mean_mrr: 0.0651 - g_auc: 0.8782 - val_loss: 0.3798 - val_ndcg_5: 0.5318 - val_ndcg_10: 0.5318 - val_mean_mrr: 0.0674 - val_g_auc: 0.9018\n",
      "Epoch 3/10\n",
      "705/709 [============================>.] - ETA: 0s - loss: 0.4025 - ndcg_5: 0.5092 - ndcg_10: 0.5092 - mean_mrr: 0.0646 - g_auc: 0.8989\n",
      "\n",
      "Epoch 3: \n",
      "- loss: 0.4023, \n",
      "- ndcg_5: 0.5106, \n",
      "- ndcg_10: 0.5106, \n",
      "- mean_mrr: 0.0648, \n",
      "- g_auc: 0.8990, \n",
      "- val_loss: 0.3628, \n",
      "- val_ndcg_5: 0.5318, \n",
      "- val_ndcg_10: 0.5318, \n",
      "- val_mean_mrr: 0.0674, \n",
      "- val_g_auc: 0.9122, \n",
      "\n",
      "709/709 [==============================] - 1s 2ms/step - loss: 0.4023 - ndcg_5: 0.5106 - ndcg_10: 0.5106 - mean_mrr: 0.0648 - g_auc: 0.8990 - val_loss: 0.3628 - val_ndcg_5: 0.5318 - val_ndcg_10: 0.5318 - val_mean_mrr: 0.0674 - val_g_auc: 0.9122\n",
      "Epoch 4/10\n",
      "669/709 [===========================>..] - ETA: 0s - loss: 0.3757 - ndcg_5: 0.4993 - ndcg_10: 0.4993 - mean_mrr: 0.0633 - g_auc: 0.9131\n",
      "\n",
      "Epoch 4: \n",
      "- loss: 0.3742, \n",
      "- ndcg_5: 0.4965, \n",
      "- ndcg_10: 0.4965, \n",
      "- mean_mrr: 0.0630, \n",
      "- g_auc: 0.9141, \n",
      "- val_loss: 0.3354, \n",
      "- val_ndcg_5: 0.5318, \n",
      "- val_ndcg_10: 0.5318, \n",
      "- val_mean_mrr: 0.0674, \n",
      "- val_g_auc: 0.9224, \n",
      "\n",
      "709/709 [==============================] - 1s 2ms/step - loss: 0.3742 - ndcg_5: 0.4965 - ndcg_10: 0.4965 - mean_mrr: 0.0630 - g_auc: 0.9141 - val_loss: 0.3354 - val_ndcg_5: 0.5318 - val_ndcg_10: 0.5318 - val_mean_mrr: 0.0674 - val_g_auc: 0.9224\n",
      "Epoch 5/10\n",
      "697/709 [============================>.] - ETA: 0s - loss: 0.3502 - ndcg_5: 0.5294 - ndcg_10: 0.5294 - mean_mrr: 0.0671 - g_auc: 0.9251\n",
      "\n",
      "Epoch 5: \n",
      "- loss: 0.3504, \n",
      "- ndcg_5: 0.5289, \n",
      "- ndcg_10: 0.5289, \n",
      "- mean_mrr: 0.0672, \n",
      "- g_auc: 0.9250, \n",
      "- val_loss: 0.3414, \n",
      "- val_ndcg_5: 0.5318, \n",
      "- val_ndcg_10: 0.5318, \n",
      "- val_mean_mrr: 0.0674, \n",
      "- val_g_auc: 0.9277, \n",
      "\n",
      "709/709 [==============================] - 1s 2ms/step - loss: 0.3504 - ndcg_5: 0.5289 - ndcg_10: 0.5289 - mean_mrr: 0.0672 - g_auc: 0.9250 - val_loss: 0.3414 - val_ndcg_5: 0.5318 - val_ndcg_10: 0.5318 - val_mean_mrr: 0.0674 - val_g_auc: 0.9277\n",
      "Epoch 6/10\n",
      "677/709 [===========================>..] - ETA: 0s - loss: 0.3327 - ndcg_5: 0.4860 - ndcg_10: 0.4860 - mean_mrr: 0.0616 - g_auc: 0.9341\n",
      "\n",
      "Epoch 6: \n",
      "- loss: 0.3317, \n",
      "- ndcg_5: 0.4866, \n",
      "- ndcg_10: 0.4866, \n",
      "- mean_mrr: 0.0618, \n",
      "- g_auc: 0.9343, \n",
      "- val_loss: 0.3304, \n",
      "- val_ndcg_5: 0.5318, \n",
      "- val_ndcg_10: 0.5318, \n",
      "- val_mean_mrr: 0.0674, \n",
      "- val_g_auc: 0.9325, \n",
      "\n",
      "709/709 [==============================] - 1s 2ms/step - loss: 0.3317 - ndcg_5: 0.4866 - ndcg_10: 0.4866 - mean_mrr: 0.0618 - g_auc: 0.9343 - val_loss: 0.3304 - val_ndcg_5: 0.5318 - val_ndcg_10: 0.5318 - val_mean_mrr: 0.0674 - val_g_auc: 0.9325\n",
      "Epoch 7/10\n",
      "699/709 [============================>.] - ETA: 0s - loss: 0.3158 - ndcg_5: 0.5122 - ndcg_10: 0.5122 - mean_mrr: 0.0650 - g_auc: 0.9401\n",
      "\n",
      "Epoch 7: \n",
      "- loss: 0.3161, \n",
      "- ndcg_5: 0.5148, \n",
      "- ndcg_10: 0.5148, \n",
      "- mean_mrr: 0.0654, \n",
      "- g_auc: 0.9400, \n",
      "- val_loss: 0.3152, \n",
      "- val_ndcg_5: 0.5318, \n",
      "- val_ndcg_10: 0.5318, \n",
      "- val_mean_mrr: 0.0674, \n",
      "- val_g_auc: 0.9319, \n",
      "\n",
      "709/709 [==============================] - 1s 2ms/step - loss: 0.3161 - ndcg_5: 0.5148 - ndcg_10: 0.5148 - mean_mrr: 0.0654 - g_auc: 0.9400 - val_loss: 0.3152 - val_ndcg_5: 0.5318 - val_ndcg_10: 0.5318 - val_mean_mrr: 0.0674 - val_g_auc: 0.9319\n",
      "Epoch 8/10\n",
      "707/709 [============================>.] - ETA: 0s - loss: 0.3014 - ndcg_5: 0.4682 - ndcg_10: 0.4682 - mean_mrr: 0.0594 - g_auc: 0.9452\n",
      "\n",
      "Epoch 8: \n",
      "- loss: 0.3016, \n",
      "- ndcg_5: 0.4683, \n",
      "- ndcg_10: 0.4683, \n",
      "- mean_mrr: 0.0594, \n",
      "- g_auc: 0.9451, \n",
      "- val_loss: 0.3057, \n",
      "- val_ndcg_5: 0.5318, \n",
      "- val_ndcg_10: 0.5318, \n",
      "- val_mean_mrr: 0.0674, \n",
      "- val_g_auc: 0.9342, \n",
      "\n",
      "709/709 [==============================] - 1s 2ms/step - loss: 0.3016 - ndcg_5: 0.4683 - ndcg_10: 0.4683 - mean_mrr: 0.0594 - g_auc: 0.9451 - val_loss: 0.3057 - val_ndcg_5: 0.5318 - val_ndcg_10: 0.5318 - val_mean_mrr: 0.0674 - val_g_auc: 0.9342\n",
      "Epoch 9/10\n",
      "685/709 [===========================>..] - ETA: 0s - loss: 0.2895 - ndcg_5: 0.5168 - ndcg_10: 0.5168 - mean_mrr: 0.0655 - g_auc: 0.9493\n",
      "\n",
      "Epoch 9: \n",
      "- loss: 0.2900, \n",
      "- ndcg_5: 0.5148, \n",
      "- ndcg_10: 0.5148, \n",
      "- mean_mrr: 0.0653, \n",
      "- g_auc: 0.9491, \n",
      "- val_loss: 0.3048, \n",
      "- val_ndcg_5: 0.5318, \n",
      "- val_ndcg_10: 0.5318, \n",
      "- val_mean_mrr: 0.0674, \n",
      "- val_g_auc: 0.9374, \n",
      "\n",
      "709/709 [==============================] - 1s 2ms/step - loss: 0.2900 - ndcg_5: 0.5148 - ndcg_10: 0.5148 - mean_mrr: 0.0653 - g_auc: 0.9491 - val_loss: 0.3048 - val_ndcg_5: 0.5318 - val_ndcg_10: 0.5318 - val_mean_mrr: 0.0674 - val_g_auc: 0.9374\n",
      "Epoch 10/10\n",
      "683/709 [===========================>..] - ETA: 0s - loss: 0.2803 - ndcg_5: 0.5212 - ndcg_10: 0.5212 - mean_mrr: 0.0661 - g_auc: 0.9533\n",
      "\n",
      "Epoch 10: \n",
      "- loss: 0.2805, \n",
      "- ndcg_5: 0.5205, \n",
      "- ndcg_10: 0.5205, \n",
      "- mean_mrr: 0.0660, \n",
      "- g_auc: 0.9531, \n",
      "- val_loss: 0.2987, \n",
      "- val_ndcg_5: 0.5318, \n",
      "- val_ndcg_10: 0.5318, \n",
      "- val_mean_mrr: 0.0674, \n",
      "- val_g_auc: 0.9373, \n",
      "\n",
      "709/709 [==============================] - 1s 2ms/step - loss: 0.2805 - ndcg_5: 0.5205 - ndcg_10: 0.5205 - mean_mrr: 0.0660 - g_auc: 0.9531 - val_loss: 0.2987 - val_ndcg_5: 0.5318 - val_ndcg_10: 0.5318 - val_mean_mrr: 0.0674 - val_g_auc: 0.9373\n"
     ]
    }
   ],
   "source": [
    "class CustomMetricsCallback(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        logs = logs or {}\n",
    "        print(f\"\\n\\nEpoch {epoch+1}:\", end=\" \")\n",
    "        for key, value in logs.items():\n",
    "            print(f\"\\n- {key}: {value:.4f}\", end=\", \")\n",
    "        print(\"\\n\")\n",
    "\n",
    "# Using the custom callback\n",
    "custom_metrics_callback = CustomMetricsCallback()\n",
    "# Train the model\n",
    "history = content_based_model.fit(\n",
    "    X_train, \n",
    "    y_train, \n",
    "    epochs=10, \n",
    "    batch_size=32,\n",
    "    validation_data=(X_val, y_val),\n",
    "    callbacks=[custom_metrics_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model_optimized(model, user_profiles_df_train, articles_df, articles_embeddings_df, k=10, num_users=2000):\n",
    "    embeddings_dict = articles_embeddings_df.T.to_dict('list')\n",
    "    precisions = []\n",
    "    recalls = []\n",
    "    mrrs = []\n",
    "    ndcgs = []\n",
    "    \n",
    "    all_true_labels = []\n",
    "    all_scores = []\n",
    "\n",
    "    sampled_user_profiles_df = user_profiles_df_train.sample(n=num_users, random_state=42)\n",
    "    \n",
    "    for _, user in tqdm(sampled_user_profiles_df.iterrows(), total=num_users, desc=\"Evaluating\", ncols=100):\n",
    "        user_embedding = user['user_embedding']\n",
    "        user_id = user['user_id']\n",
    "        clicked_articles = set(user['click_article_id'])\n",
    "\n",
    "        all_embeddings = []\n",
    "        article_ids = []\n",
    "        for article_id in articles_df['article_id']:\n",
    "            if article_id in embeddings_dict:\n",
    "                article_embedding = embeddings_dict[article_id]\n",
    "                combined_features = np.concatenate((user_embedding, article_embedding)).reshape(1, -1)\n",
    "                all_embeddings.append(combined_features)\n",
    "                article_ids.append(article_id)\n",
    "        \n",
    "        all_embeddings = np.vstack(all_embeddings)\n",
    "        scores = model.predict(all_embeddings, verbose=0).flatten()  # Set verbose=0 to suppress model output\n",
    "        true_labels = np.array([1 if article_id in clicked_articles else 0 for article_id in article_ids])\n",
    "\n",
    "        precisions.append(precision_at_k(true_labels, scores, k))\n",
    "        recalls.append(recall_at_k(true_labels, scores, k))\n",
    "        mrrs.append(mrr(true_labels, scores))\n",
    "        ndcgs.append(ndcg_at_k(true_labels, scores, k))\n",
    "        \n",
    "        all_true_labels.extend(true_labels)\n",
    "        all_scores.extend(scores)\n",
    "\n",
    "    avg_precision = np.mean(precisions)\n",
    "    avg_recall = np.mean(recalls)\n",
    "    avg_mrr = np.mean(mrrs)\n",
    "    avg_ndcg = np.mean(ndcgs)\n",
    "    g_auc = roc_auc_score(all_true_labels, all_scores)\n",
    "\n",
    "    return avg_ndcg, avg_mrr, avg_precision, avg_recall, g_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_test, y_test = prepare_training_data(user_test_profiles_df, df_articles, article_embeddings_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|███████████████████████████████████████████████████| 10/10 [00:09<00:00,  1.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NDCG@10: 0.0693, MRR: 0.1359, precision: 0.0200, recall: 0.0625, g_auc: 0.9147\n"
     ]
    }
   ],
   "source": [
    "# ndcg_score, mrr_score, auc_score, y_pred = evaluate_model_on_test_data(content_based_model, X_test, y_test)\n",
    "# print(f\"NDCG@10: {ndcg_score:.4f}, MRR: {mrr_score:.4f}, AUC: {auc_score:.4f}\")\n",
    "# Evaluation\n",
    "# ndcg_score, mrr_score, g_auc_score, y_true, y_pred, user_ids = evaluate_model_optimized(content_based_model, user_profiles_df_test, df_articles, article_embeddings_df, k=10, num_users=len(user_profiles_df_test))\n",
    "avg_ndcg, avg_mrr, avg_precision, avg_recall, g_auc = evaluate_model_optimized(content_based_model, user_profiles_df_test, df_articles, article_embeddings_df, k=10, num_users=10)\n",
    "print(f\"NDCG@10: {avg_ndcg:.4f}, MRR: {avg_mrr:.4f}, precision: {avg_precision:.4f}, recall: {avg_recall:.4f}, g_auc: {g_auc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluating: 100%|███████████████████████████████████████████████████| 10/10 [00:08<00:00,  1.13it/s]\n",
    "# NDCG@10: 0.3124, MRR: 0.3869, precision: 0.1400, recall: 0.4244, g_auc: 0.9683"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer_top_k_articles(user_id, user_profiles_df, df_articles, article_embeddings_df, model, k=5):\n",
    "    tmp_df_articles = df_articles.copy()\n",
    "    # Retrieve the user's embedding\n",
    "    user_profile = user_profiles_df[user_profiles_df['user_id'] == user_id].iloc[0]\n",
    "    \n",
    "    if user_profile.empty:\n",
    "        raise ValueError(\"User ID not found in the user profiles.\")\n",
    "\n",
    "    user_embedding = user_profile['user_embedding']\n",
    "\n",
    "    # Get all articles embeddings\n",
    "    embeddings_dict = article_embeddings_df.T.to_dict('list')\n",
    "    \n",
    "    article_ids = []\n",
    "    combined_features_list = []\n",
    "    \n",
    "    for article_id, article_embedding in embeddings_dict.items():\n",
    "        article_ids.append(article_id)\n",
    "        combined_features = np.concatenate((user_embedding, article_embedding)).reshape(1, -1)\n",
    "        combined_features_list.append(combined_features)\n",
    "\n",
    "    all_embeddings = np.vstack(combined_features_list)\n",
    "    \n",
    "    # Predict relevance scores using the trained model\n",
    "    scores = model.predict(all_embeddings, verbose=0).flatten()\n",
    "\n",
    "    print(user_profile[\"click_article_id\"])\n",
    "    # Add scores to dataframe\n",
    "    tmp_df_articles['score'] = tmp_df_articles['article_id'].map(dict(zip(article_ids, scores)))\n",
    "    tmp_df_articles = tmp_df_articles.sort_values(by='score', ascending=False)\n",
    "\n",
    "    top_articles = tmp_df_articles.copy()[[\"article_id\",\"category_id\",\"score\"]]\n",
    "    user_article_clicked = top_articles[top_articles['article_id'].isin(user_profile[\"click_article_id\"])].reset_index(drop=True)\n",
    "\n",
    "    top_articles = top_articles[~top_articles['article_id'].isin(user_profile[\"click_article_id\"])]\n",
    "\n",
    "    # Rank articles based on scores\n",
    "    top_k_indices = np.argsort(scores)[-k:][::-1]\n",
    "    top_k_article_ids = [article_ids[i] for i in top_k_indices]\n",
    "    \n",
    "    # Rank articles based on scores (worst)\n",
    "    bottom_k_indices = np.argsort(scores)[:k]\n",
    "    bottom_k_article_ids = [article_ids[i] for i in bottom_k_indices]\n",
    "\n",
    "    # Fetch top K articles metadata\n",
    "    top_k_articles = top_articles[top_articles['article_id'].isin(top_k_article_ids)].reset_index(drop=True)\n",
    "    bottom_k_article_ids = top_articles[top_articles['article_id'].isin(bottom_k_article_ids)].reset_index(drop=True)\n",
    "    bottom_k_article_ids = bottom_k_article_ids.sort_values(by='score', ascending=True)\n",
    "    \n",
    "    # Display the top K articles usi\n",
    "    return top_k_articles, bottom_k_article_ids, user_article_clicked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>click_article_id</th>\n",
       "      <th>user_embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[157541, 68866, 96755, 313996, 160158, 233470,...</td>\n",
       "      <td>[-0.2103362800553441, -0.9635731801390648, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[235840, 96663, 59758, 160474, 36162, 234481, ...</td>\n",
       "      <td>[-0.20247302064672112, -0.9621158763766289, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>[236444, 234318, 236065, 236294, 234686, 23376...</td>\n",
       "      <td>[-0.5879472325054499, -0.9644155089671795, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>[336499, 271261, 48915, 44488]</td>\n",
       "      <td>[-0.010430984199047089, -0.9642642736434937, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>[124228, 283776, 286310, 237257, 156619, 27155...</td>\n",
       "      <td>[-0.09797036762548876, -0.9608012786933354, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294657</th>\n",
       "      <td>322890</td>\n",
       "      <td>[62464, 10023]</td>\n",
       "      <td>[-0.19085068255662918, -0.9595281183719635, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294658</th>\n",
       "      <td>322892</td>\n",
       "      <td>[42567, 39894]</td>\n",
       "      <td>[-0.19202575460076332, -0.9561611711978912, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294659</th>\n",
       "      <td>322893</td>\n",
       "      <td>[50644, 36162]</td>\n",
       "      <td>[0.29815271496772766, -0.9459012746810913, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294660</th>\n",
       "      <td>322895</td>\n",
       "      <td>[289197, 63746]</td>\n",
       "      <td>[-0.15992705523967743, -0.9621853232383728, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294661</th>\n",
       "      <td>322896</td>\n",
       "      <td>[30760, 157507]</td>\n",
       "      <td>[-0.23920656740665436, -0.9676742255687714, -0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>294662 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        user_id                                   click_article_id  \\\n",
       "0             0  [157541, 68866, 96755, 313996, 160158, 233470,...   \n",
       "1             1  [235840, 96663, 59758, 160474, 36162, 234481, ...   \n",
       "2             3  [236444, 234318, 236065, 236294, 234686, 23376...   \n",
       "3             4                     [336499, 271261, 48915, 44488]   \n",
       "4             5  [124228, 283776, 286310, 237257, 156619, 27155...   \n",
       "...         ...                                                ...   \n",
       "294657   322890                                     [62464, 10023]   \n",
       "294658   322892                                     [42567, 39894]   \n",
       "294659   322893                                     [50644, 36162]   \n",
       "294660   322895                                    [289197, 63746]   \n",
       "294661   322896                                    [30760, 157507]   \n",
       "\n",
       "                                           user_embedding  \n",
       "0       [-0.2103362800553441, -0.9635731801390648, -0....  \n",
       "1       [-0.20247302064672112, -0.9621158763766289, -0...  \n",
       "2       [-0.5879472325054499, -0.9644155089671795, -0....  \n",
       "3       [-0.010430984199047089, -0.9642642736434937, -...  \n",
       "4       [-0.09797036762548876, -0.9608012786933354, -0...  \n",
       "...                                                   ...  \n",
       "294657  [-0.19085068255662918, -0.9595281183719635, 0....  \n",
       "294658  [-0.19202575460076332, -0.9561611711978912, -0...  \n",
       "294659  [0.29815271496772766, -0.9459012746810913, -0....  \n",
       "294660  [-0.15992705523967743, -0.9621853232383728, 0....  \n",
       "294661  [-0.23920656740665436, -0.9676742255687714, -0...  \n",
       "\n",
       "[294662 rows x 3 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_profiles_df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[336499, 271261, 48915, 44488, 195887, 195084, 63307]\n"
     ]
    }
   ],
   "source": [
    "user_id=3\n",
    "user_id=4\n",
    "top_k_articles, bottom_k_article_ids, user_article_clicked = infer_top_k_articles(user_id, user_profiles_df_all, df_articles, article_embeddings_df, content_based_model, k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>category_id</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>195887</td>\n",
       "      <td>317</td>\n",
       "      <td>0.999075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>195084</td>\n",
       "      <td>317</td>\n",
       "      <td>0.999071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>63307</td>\n",
       "      <td>132</td>\n",
       "      <td>0.986042</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   article_id  category_id     score\n",
       "0      195887          317  0.999075\n",
       "1      195084          317  0.999071\n",
       "2       63307          132  0.986042"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_article_clicked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>category_id</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>194617</td>\n",
       "      <td>317</td>\n",
       "      <td>0.999978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>192943</td>\n",
       "      <td>317</td>\n",
       "      <td>0.999973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>195125</td>\n",
       "      <td>317</td>\n",
       "      <td>0.999950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>199197</td>\n",
       "      <td>323</td>\n",
       "      <td>0.999947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>195643</td>\n",
       "      <td>317</td>\n",
       "      <td>0.999937</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   article_id  category_id     score\n",
       "0      194617          317  0.999978\n",
       "1      192943          317  0.999973\n",
       "2      195125          317  0.999950\n",
       "3      199197          323  0.999947\n",
       "4      195643          317  0.999937"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_k_articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>category_id</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>323476</td>\n",
       "      <td>434</td>\n",
       "      <td>0.000010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>340621</td>\n",
       "      <td>438</td>\n",
       "      <td>0.000012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>254178</td>\n",
       "      <td>389</td>\n",
       "      <td>0.000012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>323508</td>\n",
       "      <td>434</td>\n",
       "      <td>0.000017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>259554</td>\n",
       "      <td>395</td>\n",
       "      <td>0.000025</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   article_id  category_id     score\n",
       "4      323476          434  0.000010\n",
       "3      340621          438  0.000012\n",
       "2      254178          389  0.000012\n",
       "1      323508          434  0.000017\n",
       "0      259554          395  0.000025"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bottom_k_article_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/m/dev/6be709c0/oc-ai-engineer/OC/P10/venv/lib/python3.8/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "content_based_model.save('./input/content-based.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save DataFrames to disk\n",
    "user_profiles_df_all.to_pickle(\"./input/user_profiles_df_all.pkl\")\n",
    "df_articles.to_pickle(\"./input/df_articles.pkl\")\n",
    "article_embeddings_df.to_pickle(\"./input/article_embeddings_df.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(46033, 250)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "article_embeddings_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
